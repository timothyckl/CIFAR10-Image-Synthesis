{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: Conditional DCGAN with Instance Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from IPython import display\n",
    "from tensorflow.data import Dataset\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Conv2DTranspose, Embedding, Reshape, Flatten, Dropout, BatchNormalization, ReLU, LeakyReLU, MaxPooling2D, Concatenate\n",
    "from tensorflow_addons.layers import InstanceNormalization\n",
    "\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from utils import FrechetInceptionDistance\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.dpi': 120})\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set gpu memory growth\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = 'data\\cifar10.tfrecords'\n",
    "dataset = Dataset.load(FILE_PATH)\n",
    "print(dataset.element_spec)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator(latent_dim):\n",
    "    # foundation for label embeedded input\n",
    "    label_input = Input(shape=(1,), name='label_input')\n",
    "    label_embedding = Embedding(10, 10, name='label_embedding')(label_input)\n",
    "    \n",
    "    # linear activation\n",
    "    label_embedding = Dense(4 * 4, name='label_dense')(label_embedding)\n",
    "\n",
    "    # reshape to additional channel\n",
    "    label_embedding = Reshape((4, 4, 1), name='label_reshape')(label_embedding)\n",
    "    assert label_embedding.shape == (None, 4, 4, 1)\n",
    "\n",
    "    # foundation for 4x4 image input\n",
    "    noise_input = Input(shape=(latent_dim,), name='noise_input')\n",
    "    noise_dense = Dense(4 * 4 * 128, name='noise_dense')(noise_input)\n",
    "    noise_dense = ReLU(name='noise_relu')(noise_dense)\n",
    "    noise_reshape = Reshape((4, 4, 128), name='noise_reshape')(noise_dense)\n",
    "    assert noise_reshape.shape == (None, 4, 4, 128)\n",
    "\n",
    "    # concatenate label embedding and image to produce 129-channel output\n",
    "    concat = keras.layers.Concatenate(name='concatenate')([noise_reshape, label_embedding])\n",
    "    assert concat.shape == (None, 4, 4, 129)\n",
    "\n",
    "    # upsample to 8x8\n",
    "    conv1 = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', name='conv1')(concat)\n",
    "    assert conv1.shape == (None, 8, 8, 128)\n",
    "    conv1 = InstanceNormalization(name='conv1_norm')(conv1)\n",
    "    conv1 = ReLU(name='conv1_relu')(conv1)\n",
    "\n",
    "    # upsample to 16x16\n",
    "    conv2 = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', name='conv2')(conv1)\n",
    "    assert conv2.shape == (None, 16, 16, 128)\n",
    "    conv2 = InstanceNormalization(name='conv2_norm')(conv2)\n",
    "    conv2 = ReLU(name='conv2_relu')(conv2)\n",
    "\n",
    "    # upsample to 32x32\n",
    "    conv3 = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', name='conv3')(conv2)\n",
    "    assert conv3.shape == (None, 32, 32, 128)\n",
    "    conv3 = InstanceNormalization(name='conv3_norm')(conv3)\n",
    "    conv3 = ReLU(name='conv3_relu')(conv3)\n",
    "\n",
    "    # output 32x32x3\n",
    "    output = Conv2D(3, (3, 3), activation='tanh', padding='same', name='output')(conv3)\n",
    "    assert output.shape == (None, 32, 32, 3)\n",
    "\n",
    "    model = Model(inputs=[noise_input, label_input], outputs=output, name='generator')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_generator(latent_dim=128).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize generator\n",
    "# plot_model(generator, show_shapes=True, to_file='images\\model_architecture\\Conditional_DCGAN\\generator.png')\n",
    "# generator_img = mpimg.imread('images\\model_architecture\\Conditional_DCGAN\\generator.png')\n",
    "\n",
    "# plt.figure(figsize=(20, 20))\n",
    "# imgplot = plt.imshow(generator_img)\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discriminator():\n",
    "    # foundation for label embeedded input\n",
    "    label_input = Input(shape=(1,), name='label_input')\n",
    "    label_embedding = Embedding(10, 10, name='label_embedding')(label_input)\n",
    "    \n",
    "    # linear activation\n",
    "    label_embedding = Dense(32 * 32, name='label_dense')(label_embedding)\n",
    "    \n",
    "    # reshape to additional channel\n",
    "    label_embedding = Reshape((32, 32, 1), name='label_reshape')(label_embedding)\n",
    "    assert label_embedding.shape == (None, 32, 32, 1)\n",
    "\n",
    "    # foundation for 32x32 image input\n",
    "    image_input = Input(shape=(32, 32, 3), name='image_input')\n",
    "\n",
    "    # concatenate label embedding and image to produce 129-channel input\n",
    "    concat = keras.layers.Concatenate(name='concatenate')([image_input, label_embedding])\n",
    "    assert concat.shape == (None, 32, 32, 4)\n",
    "\n",
    "    # downsample to 16x16\n",
    "    conv1 = Conv2D(128, kernel_size=3, strides=2, padding='same', name='conv1')(concat)\n",
    "    assert conv1.shape == (None, 16, 16, 128)\n",
    "    # conv1 = InstanceNormalization(name='conv1_norm')(conv1)\n",
    "    conv1 = LeakyReLU(alpha=0.2, name='conv1_leaky_relu')(conv1)\n",
    "    \n",
    "    # downsample to 8x8\n",
    "    conv2 = Conv2D(128, kernel_size=3, strides=2, padding='same', name='conv2')(conv1)\n",
    "    assert conv2.shape == (None, 8, 8, 128)\n",
    "    conv2 = LeakyReLU(alpha=0.2, name='conv2_leaky_relu')(conv2)\n",
    "    \n",
    "    # downsample to 4x4\n",
    "    conv3 = Conv2D(128, kernel_size=3, strides=2, padding='same', name='conv3')(conv2)\n",
    "    assert conv3.shape == (None, 4, 4, 128)\n",
    "    conv3 = LeakyReLU(alpha=0.2, name='conv3_leaky_relu')(conv3)\n",
    "\n",
    "    # flatten feature maps\n",
    "    flat = Flatten(name='flatten')(conv3)\n",
    "    \n",
    "    output = Dense(units=1, activation='sigmoid', name='output')(flat)\n",
    "\n",
    "    model = Model(inputs=[image_input, label_input], outputs=output, name='discriminator')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_discriminator().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize discriminator\n",
    "# plot_model(discriminator, show_shapes=True, to_file='images\\model_architecture\\Conditional_DCGAN\\discriminator.png')\n",
    "# discriminator_img = mpimg.imread('images\\model_architecture\\Conditional_DCGAN\\discriminator.png')\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# imgplot = plt.imshow(discriminator_img)\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining cDCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalDCGAN(Model):\n",
    "    def __init__(self, generator, discriminator, latent_dim):\n",
    "        super(ConditionalDCGAN, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(ConditionalDCGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.g_loss_metric = keras.metrics.Mean(name='g_loss')\n",
    "        self.d_real_loss_metric = keras.metrics.Mean(name='d_real_loss')\n",
    "        self.d_fake_loss_metric = keras.metrics.Mean(name='d_fake_loss')\n",
    "        self.d_acc_metric = keras.metrics.BinaryAccuracy(name='d_acc')\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.g_loss_metric, self.d_real_loss_metric, self.d_fake_loss_metric, self.d_acc_metric]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        real_images, class_labels = data\n",
    "        class_labels = tf.cast(class_labels, 'int32')\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "\n",
    "        # train discriminator\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_class_labels = tf.random.uniform(shape=(batch_size, 1), minval=0, maxval=10, dtype='int32')\n",
    "\n",
    "        fake_labels = tf.zeros((batch_size, 1))  # (batch_size, 1)\n",
    "        real_labels = tf.ones((batch_size, 1))  # (batch_size, 1)\n",
    "\n",
    "        # freeze generator\n",
    "        self.discriminator.trainable = True\n",
    "        self.generator.trainable = False\n",
    "    \n",
    "        with tf.GradientTape() as disc_tape:\n",
    "            disc_tape.watch(self.discriminator.trainable_variables)\n",
    "            generated_images = self.generator([random_latent_vectors, random_class_labels], training=True)\n",
    "            real_output = self.discriminator([real_images, class_labels], training=True)\n",
    "            fake_output = self.discriminator([generated_images, random_class_labels], training=True)\n",
    "            d_loss_real = self.loss_fn(real_labels, real_output)\n",
    "            d_loss_fake = self.loss_fn(fake_labels, fake_output)\n",
    "            d_loss = d_loss_real + d_loss_fake  # log(D(x)) + log(1 - D(G(z))\n",
    "        \n",
    "        disc_grads = disc_tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "        self.d_optimizer.apply_gradients(zip(disc_grads, self.discriminator.trainable_variables))\n",
    "\n",
    "        # train the generator\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_class_labels = tf.random.uniform(shape=(batch_size, 1), minval=0, maxval=10, dtype='int32')\n",
    "        misleading_labels = tf.ones((batch_size, 1))\n",
    "\n",
    "        # freeze discriminator\n",
    "        self.discriminator.trainable = False\n",
    "        self.generator.trainable = True\n",
    "\n",
    "        with tf.GradientTape() as gen_tape:\n",
    "            gen_tape.watch(self.generator.trainable_variables)\n",
    "            generated_images = self.generator([random_latent_vectors, random_class_labels], training=True)\n",
    "            pred_on_fake = self.discriminator([generated_images, random_class_labels], training=True)\n",
    "            # negative log probability of the discriminator making the correct choice\n",
    "            g_loss = self.loss_fn(misleading_labels, pred_on_fake)  # maximize log(D(G(z))) = minimize -log(1 - D(G(z)))\n",
    "        \n",
    "        gen_grads = gen_tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        self.g_optimizer.apply_gradients(zip(gen_grads, self.generator.trainable_variables))\n",
    "\n",
    "        # update metrics\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        self.d_real_loss_metric.update_state(d_loss_real)\n",
    "        self.d_fake_loss_metric.update_state(d_loss_fake)\n",
    "        self.d_acc_metric.update_state(real_labels, real_output)\n",
    "\n",
    "        return {\n",
    "            'g_loss': self.g_loss_metric.result(),\n",
    "            'd_real_loss': self.d_real_loss_metric.result(),\n",
    "            'd_fake_loss': self.d_fake_loss_metric.result(),\n",
    "            'd_acc': self.d_acc_metric.result()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANMonitor(Callback):\n",
    "    def __init__(self, latent_dim, label_map):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.label_map = label_map\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # plot 100 generated images and save weights every 10 epochs\n",
    "        latent_vectors = tf.random.normal(shape=(100, self.latent_dim))\n",
    "        class_labels = tf.reshape(tf.range(10), shape=(10, 1))\n",
    "        class_labels = tf.tile(class_labels, multiples=(1, 10))\n",
    "        class_labels = tf.reshape(class_labels, shape=(100, 1))\n",
    "\n",
    "        generated_images = self.model.generator([latent_vectors, class_labels], training=False)\n",
    "        generated_images = (generated_images + 1) / 2\n",
    "\n",
    "        if not os.path.exists('assets/cdcgan_inorm'):\n",
    "            os.makedirs('assets/cdcgan_inorm')\n",
    "\n",
    "        if not os.path.exists('images/cdcgan_inorm_images'):\n",
    "            os.makedirs('images/cdcgan_inorm_images')\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            if not os.path.exists(f'assets/cdcgan_inorm/epoch_{epoch + 1}'):\n",
    "                os.makedirs(f'assets/cdcgan_inorm/epoch_{epoch + 1}')\n",
    "                self.model.generator.save_weights(f'assets/cdcgan_inorm/epoch_{epoch + 1}/generator_weights_epoch_{epoch + 1}.h5')\n",
    "                self.model.discriminator.save_weights(f'assets/cdcgan_inorm/epoch_{epoch + 1}/discriminator_weights_epoch_{epoch + 1}.h5')\n",
    "                print(f'\\n\\nSaving weights at epoch {epoch + 1}\\n')\n",
    "\n",
    "            fig, axes = plt.subplots(10, 10, figsize=(20, 20))\n",
    "            axes = axes.flatten()\n",
    "\n",
    "            for i, ax in enumerate(axes):\n",
    "                ax.imshow(generated_images[i])\n",
    "                ax.set_title(self.label_map[class_labels[i].numpy().item()], fontsize=16)\n",
    "                ax.axis('off')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'images/cdcgan_inorm_images/generated_img_{epoch + 1}.png')\n",
    "            plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training cDCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "LATENT_DIM = 128    \n",
    "LEARNING_RATE = 2e-4\n",
    "BETA_1 = 0.5\n",
    "LABEL_SMOOTHING = 0.0\n",
    "\n",
    "label_map = {\n",
    "    0: 'airplane',\n",
    "    1: 'automobile',\n",
    "    2: 'bird',\n",
    "    3: 'cat',\n",
    "    4: 'deer',\n",
    "    5: 'dog',\n",
    "    6: 'frog',\n",
    "    7: 'horse',\n",
    "    8: 'ship',\n",
    "    9: 'truck'\n",
    "}\n",
    "\n",
    "callbacks = [GANMonitor(LATENT_DIM, label_map)]\n",
    "\n",
    "generator = create_generator(LATENT_DIM)\n",
    "discriminator = create_discriminator()\n",
    "cdcgan = ConditionalDCGAN(generator, discriminator, latent_dim=LATENT_DIM)\n",
    "cdcgan.compile(\n",
    "    g_optimizer=Adam(learning_rate=LEARNING_RATE, beta_1=BETA_1),\n",
    "    d_optimizer=Adam(learning_rate=LEARNING_RATE, beta_1=BETA_1),\n",
    "    loss_fn=BinaryCrossentropy(label_smoothing=LABEL_SMOOTHING)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history = cdcgan.fit(dataset, epochs=EPOCHS, callbacks=callbacks, use_multiprocessing=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "plt.plot(history.history['g_loss'], label='gen_loss')\n",
    "plt.plot(history.history['d_real_loss'], label='disc_real_loss')\n",
    "plt.plot(history.history['d_fake_loss'], label='disc_fake_loss')\n",
    "\n",
    "plt.xlabel('Epochs', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(history.history['d_acc'], label='disc_acc')\n",
    "\n",
    "plt.xlabel('Epochs', fontsize=14)\n",
    "plt.ylabel('Accuracy', fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vectors = tf.random.normal(shape=(100, LATENT_DIM))\n",
    "class_labels = tf.reshape(tf.range(10), shape=(10, 1))\n",
    "class_labels = tf.tile(class_labels, multiples=(1, 10))\n",
    "class_labels = tf.reshape(class_labels, shape=(100, 1))\n",
    "\n",
    "generated_images = cdcgan.generator([latent_vectors, class_labels], training=False)\n",
    "generated_images = (generated_images + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(10, 10, figsize=(20, 20))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(generated_images[i], cmap='gray')\n",
    "    ax.set_title(label_map[class_labels[i].numpy().item()], fontsize=18)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cbb20fadfa16e03ebe385758df0b196997ed807c890aaec95b326082f430e8b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

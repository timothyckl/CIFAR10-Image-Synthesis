{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Deep Convolutional Generative Adversarial Network (cDCGAN)\n",
    "\n",
    "This notebook will contain my implmentation of DCGAN from the paper [1] conditioning the generator and discriminator models  with label information, a concept introduced in [2]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_addons\n",
      "  Downloading tensorflow_addons-0.19.0-cp38-cp38-win_amd64.whl (742 kB)\n",
      "     ------------------------------------ 742.4/742.4 kB 219.0 kB/s eta 0:00:00\n",
      "Collecting typeguard>=2.7\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\timothy chia\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from tensorflow_addons) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\timothy chia\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from packaging->tensorflow_addons) (3.0.9)\n",
      "Installing collected packages: typeguard, tensorflow_addons\n",
      "Successfully installed tensorflow_addons-0.19.0 typeguard-2.13.3\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from IPython import display\n",
    "from tensorflow.data import Dataset\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Conv2DTranspose, Embedding, Reshape, Flatten, Dropout, BatchNormalization, ReLU, LeakyReLU, MaxPooling2D, Concatenate\n",
    "from tensorflow_addons.layers import InstanceNormalization\n",
    "\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from utils import FrechetInceptionDistance\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.dpi': 120})\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set gpu memory growth\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.uint8, name=None))\n"
     ]
    }
   ],
   "source": [
    "FILE_PATH = 'data\\cifar10.tfrecords'\n",
    "dataset = Dataset.load(FILE_PATH)\n",
    "print(dataset.element_spec)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator(latent_dim):\n",
    "    # foundation for label embeedded input\n",
    "    label_input = Input(shape=(1,), name='label_input')\n",
    "    label_embedding = Embedding(10, 10, name='label_embedding')(label_input)\n",
    "    \n",
    "    # linear activation\n",
    "    label_embedding = Dense(4 * 4, name='label_dense')(label_embedding)\n",
    "\n",
    "    # reshape to additional channel\n",
    "    label_embedding = Reshape((4, 4, 1), name='label_reshape')(label_embedding)\n",
    "    assert label_embedding.shape == (None, 4, 4, 1)\n",
    "\n",
    "    # foundation for 4x4 image input\n",
    "    noise_input = Input(shape=(latent_dim,), name='noise_input')\n",
    "    noise_dense = Dense(4 * 4 * 128, name='noise_dense')(noise_input)\n",
    "    noise_dense = ReLU(name='noise_relu')(noise_dense)\n",
    "    noise_reshape = Reshape((4, 4, 128), name='noise_reshape')(noise_dense)\n",
    "    assert noise_reshape.shape == (None, 4, 4, 128)\n",
    "\n",
    "    # concatenate label embedding and image to produce 129-channel output\n",
    "    concat = keras.layers.Concatenate(name='concatenate')([noise_reshape, label_embedding])\n",
    "    assert concat.shape == (None, 4, 4, 129)\n",
    "\n",
    "    # upsample to 8x8\n",
    "    conv1 = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', name='conv1')(concat)\n",
    "    assert conv1.shape == (None, 8, 8, 128)\n",
    "    conv1 = InstanceNormalization(name='conv1_norm')(conv1)\n",
    "    conv1 = ReLU(name='conv1_relu')(conv1)\n",
    "\n",
    "    # upsample to 16x16\n",
    "    conv2 = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', name='conv2')(conv1)\n",
    "    assert conv2.shape == (None, 16, 16, 128)\n",
    "    conv2 = InstanceNormalization(name='conv2_norm')(conv2)\n",
    "    conv2 = ReLU(name='conv2_relu')(conv2)\n",
    "\n",
    "    # upsample to 32x32\n",
    "    conv3 = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', name='conv3')(conv2)\n",
    "    assert conv3.shape == (None, 32, 32, 128)\n",
    "    conv3 = InstanceNormalization(name='conv3_norm')(conv3)\n",
    "    conv3 = ReLU(name='conv3_relu')(conv3)\n",
    "    \n",
    "    # output 32x32x3\n",
    "    output = Conv2D(3, (3, 3), activation='tanh', padding='same', name='output')(conv3)\n",
    "    assert output.shape == (None, 32, 32, 3)\n",
    "\n",
    "    model = Model(inputs=[noise_input, label_input], outputs=output, name='generator')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " noise_input (InputLayer)       [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " label_input (InputLayer)       [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " noise_dense (Dense)            (None, 2048)         264192      ['noise_input[0][0]']            \n",
      "                                                                                                  \n",
      " label_embedding (Embedding)    (None, 1, 10)        100         ['label_input[0][0]']            \n",
      "                                                                                                  \n",
      " noise_relu (ReLU)              (None, 2048)         0           ['noise_dense[0][0]']            \n",
      "                                                                                                  \n",
      " label_dense (Dense)            (None, 1, 16)        176         ['label_embedding[0][0]']        \n",
      "                                                                                                  \n",
      " noise_reshape (Reshape)        (None, 4, 4, 128)    0           ['noise_relu[0][0]']             \n",
      "                                                                                                  \n",
      " label_reshape (Reshape)        (None, 4, 4, 1)      0           ['label_dense[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 4, 4, 129)    0           ['noise_reshape[0][0]',          \n",
      "                                                                  'label_reshape[0][0]']          \n",
      "                                                                                                  \n",
      " conv1 (Conv2DTranspose)        (None, 8, 8, 128)    264320      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv1_norm (InstanceNormalizat  (None, 8, 8, 128)   256         ['conv1[0][0]']                  \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv1_relu (ReLU)              (None, 8, 8, 128)    0           ['conv1_norm[0][0]']             \n",
      "                                                                                                  \n",
      " conv2 (Conv2DTranspose)        (None, 16, 16, 128)  262272      ['conv1_relu[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_norm (InstanceNormalizat  (None, 16, 16, 128)  256        ['conv2[0][0]']                  \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_relu (ReLU)              (None, 16, 16, 128)  0           ['conv2_norm[0][0]']             \n",
      "                                                                                                  \n",
      " conv3 (Conv2DTranspose)        (None, 32, 32, 128)  262272      ['conv2_relu[0][0]']             \n",
      "                                                                                                  \n",
      " conv3_norm (InstanceNormalizat  (None, 32, 32, 128)  256        ['conv3[0][0]']                  \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_relu (ReLU)              (None, 32, 32, 128)  0           ['conv3_norm[0][0]']             \n",
      "                                                                                                  \n",
      " output (Conv2D)                (None, 32, 32, 3)    3459        ['conv3_relu[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,057,559\n",
      "Trainable params: 1,057,559\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "create_generator(latent_dim=128).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize generator\n",
    "# plot_model(generator, show_shapes=True, to_file='images\\model_architecture\\Conditional_DCGAN\\generator.png')\n",
    "# generator_img = mpimg.imread('images\\model_architecture\\Conditional_DCGAN\\generator.png')\n",
    "\n",
    "# plt.figure(figsize=(20, 20))\n",
    "# imgplot = plt.imshow(generator_img)\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discriminator():\n",
    "    # foundation for label embeedded input\n",
    "    label_input = Input(shape=(1,), name='label_input')\n",
    "    label_embedding = Embedding(10, 10, name='label_embedding')(label_input)\n",
    "    \n",
    "    # linear activation\n",
    "    label_embedding = Dense(32 * 32, name='label_dense')(label_embedding)\n",
    "    \n",
    "    # reshape to additional channel\n",
    "    label_embedding = Reshape((32, 32, 1), name='label_reshape')(label_embedding)\n",
    "    assert label_embedding.shape == (None, 32, 32, 1)\n",
    "\n",
    "    # foundation for 32x32 image input\n",
    "    image_input = Input(shape=(32, 32, 3), name='image_input')\n",
    "\n",
    "    # concatenate label embedding and image to produce 129-channel input\n",
    "    concat = keras.layers.Concatenate(name='concatenate')([image_input, label_embedding])\n",
    "    assert concat.shape == (None, 32, 32, 4)\n",
    "\n",
    "    # downsample to 16x16\n",
    "    conv1 = Conv2D(128, kernel_size=3, strides=2, padding='same', name='conv1')(concat)\n",
    "    assert conv1.shape == (None, 16, 16, 128)\n",
    "    conv1 = InstanceNormalization(name='conv1_norm')(conv1)\n",
    "    conv1 = LeakyReLU(alpha=0.2, name='conv1_leaky_relu')(conv1)\n",
    "    \n",
    "    # downsample to 8x8\n",
    "    conv2 = Conv2D(128, kernel_size=3, strides=2, padding='same', name='conv2')(conv1)\n",
    "    assert conv2.shape == (None, 8, 8, 128)\n",
    "    conv2 = InstanceNormalization(name='conv2_norm')(conv2)\n",
    "    conv2 = LeakyReLU(alpha=0.2, name='conv2_leaky_relu')(conv2)\n",
    "    \n",
    "    # downsample to 4x4\n",
    "    conv3 = Conv2D(128, kernel_size=3, strides=2, padding='same', name='conv3')(conv2)\n",
    "    assert conv3.shape == (None, 4, 4, 128)\n",
    "    conv3 = InstanceNormalization(name='conv3_norm')(conv3)\n",
    "    conv3 = LeakyReLU(alpha=0.2, name='conv3_leaky_relu')(conv3)\n",
    "\n",
    "    # flatten feature maps\n",
    "    flat = Flatten(name='flatten')(conv3)\n",
    "    \n",
    "    output = Dense(units=1, activation='sigmoid', name='output')(flat)\n",
    "\n",
    "    model = Model(inputs=[image_input, label_input], outputs=output, name='discriminator')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " label_input (InputLayer)       [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " label_embedding (Embedding)    (None, 1, 10)        100         ['label_input[0][0]']            \n",
      "                                                                                                  \n",
      " label_dense (Dense)            (None, 1, 1024)      11264       ['label_embedding[0][0]']        \n",
      "                                                                                                  \n",
      " image_input (InputLayer)       [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " label_reshape (Reshape)        (None, 32, 32, 1)    0           ['label_dense[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 32, 32, 4)    0           ['image_input[0][0]',            \n",
      "                                                                  'label_reshape[0][0]']          \n",
      "                                                                                                  \n",
      " conv1 (Conv2D)                 (None, 16, 16, 128)  4736        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv1_norm (InstanceNormalizat  (None, 16, 16, 128)  256        ['conv1[0][0]']                  \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv1_leaky_relu (LeakyReLU)   (None, 16, 16, 128)  0           ['conv1_norm[0][0]']             \n",
      "                                                                                                  \n",
      " conv2 (Conv2D)                 (None, 8, 8, 128)    147584      ['conv1_leaky_relu[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_norm (InstanceNormalizat  (None, 8, 8, 128)   256         ['conv2[0][0]']                  \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_leaky_relu (LeakyReLU)   (None, 8, 8, 128)    0           ['conv2_norm[0][0]']             \n",
      "                                                                                                  \n",
      " conv3 (Conv2D)                 (None, 4, 4, 128)    147584      ['conv2_leaky_relu[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_norm (InstanceNormalizat  (None, 4, 4, 128)   256         ['conv3[0][0]']                  \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_leaky_relu (LeakyReLU)   (None, 4, 4, 128)    0           ['conv3_norm[0][0]']             \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2048)         0           ['conv3_leaky_relu[0][0]']       \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            2049        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 314,085\n",
      "Trainable params: 314,085\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "create_discriminator().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize discriminator\n",
    "# plot_model(discriminator, show_shapes=True, to_file='images\\model_architecture\\Conditional_DCGAN\\discriminator.png')\n",
    "# discriminator_img = mpimg.imread('images\\model_architecture\\Conditional_DCGAN\\discriminator.png')\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# imgplot = plt.imshow(discriminator_img)\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining cDCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalDCGAN(Model):\n",
    "    def __init__(self, generator, discriminator, latent_dim):\n",
    "        super(ConditionalDCGAN, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(ConditionalDCGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.g_loss_metric = keras.metrics.Mean(name='g_loss')\n",
    "        self.d_loss_metric = keras.metrics.Mean(name='d_loss')\n",
    "        self.d_acc_metric = keras.metrics.BinaryAccuracy(name='d_acc')\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.g_loss_metric, self.d_loss_metric, self.d_acc_metric]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        real_images, class_labels = data\n",
    "        class_labels = tf.cast(class_labels, 'int32')\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "\n",
    "        # train discriminator\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_class_labels = tf.random.uniform(shape=(batch_size, 1), minval=0, maxval=10, dtype='int32')\n",
    "        generated_images = self.generator([random_latent_vectors, random_class_labels], training=False)\n",
    "\n",
    "        # combine real and generated images as well as real and generated labels\n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "        combined_class_labels = tf.concat([random_class_labels, class_labels], axis=0)\n",
    "\n",
    "        fake_labels = tf.zeros((batch_size, 1))  # (batch_size, 1)\n",
    "        real_labels = tf.ones((batch_size, 1))  # (batch_size, 1)\n",
    "        combined_labels = tf.concat([fake_labels, real_labels], axis=0)  # (2*batch_size, 1)\n",
    "\n",
    "        # train the discriminator\n",
    "        with tf.GradientTape() as disc_tape:\n",
    "            pred_on_combined = self.discriminator([combined_images, combined_class_labels], training=True)\n",
    "            d_loss = self.loss_fn(combined_labels, pred_on_combined)  # log(D(x)) + log(1 - D(G(z))\n",
    "        \n",
    "        disc_grads = disc_tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "        self.d_optimizer.apply_gradients(zip(disc_grads, self.discriminator.trainable_variables))\n",
    "\n",
    "        # train the generator\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_class_labels = tf.random.uniform(shape=(batch_size, 1), minval=0, maxval=10, dtype='int32')\n",
    "        misleading_labels = tf.ones((batch_size, 1))\n",
    "\n",
    "        with tf.GradientTape() as gen_tape:\n",
    "            pred_on_fake = self.discriminator([self.generator([random_latent_vectors, random_class_labels], training=True), random_class_labels], training=False)\n",
    "            g_loss = self.loss_fn(misleading_labels, pred_on_fake)  # maximize log(D(G(z))) = minimize -log(1 - D(G(z)))\n",
    "        \n",
    "        gen_grads = gen_tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        self.g_optimizer.apply_gradients(zip(gen_grads, self.generator.trainable_variables))\n",
    "\n",
    "        # update metrics\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        self.d_acc_metric.update_state(combined_labels, pred_on_combined)\n",
    "\n",
    "        return {\n",
    "            'g_loss': self.g_loss_metric.result(), \n",
    "            'd_loss': self.d_loss_metric.result(),\n",
    "            'd_acc': self.d_acc_metric.result()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANMonitor(Callback):\n",
    "    def __init__(self, latent_dim, label_map):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.label_map = label_map\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # plot 100 generated images and save weights every 10 epochs\n",
    "        latent_vectors = tf.random.normal(shape=(100, self.latent_dim))\n",
    "        class_labels = tf.reshape(tf.range(10), shape=(10, 1))\n",
    "        class_labels = tf.tile(class_labels, multiples=(1, 10))\n",
    "        class_labels = tf.reshape(class_labels, shape=(100, 1))\n",
    "\n",
    "        generated_images = self.model.generator([latent_vectors, class_labels], training=False)\n",
    "        generated_images = (generated_images + 1) / 2\n",
    "\n",
    "        if not os.path.exists('assets/cdcgan'):\n",
    "            os.makedirs('assets/cdcgan')\n",
    "\n",
    "        if not os.path.exists('images/cdcgan_images'):\n",
    "            os.makedirs('images/cdcgan_images')\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            if not os.path.exists(f'assets/cdcgan/epoch_{epoch + 1}'):\n",
    "                os.makedirs(f'assets/cdcgan/epoch_{epoch + 1}')\n",
    "                self.model.generator.save_weights(f'assets/cdcgan/epoch_{epoch + 1}/generator_weights_epoch_{epoch + 1}.h5')\n",
    "                self.model.discriminator.save_weights(f'assets/cdcgan/epoch_{epoch + 1}/discriminator_weights_epoch_{epoch + 1}.h5')\n",
    "                print(f'\\n\\nSaving weights at epoch {epoch + 1}\\n')\n",
    "\n",
    "            fig, axes = plt.subplots(10, 10, figsize=(20, 20))\n",
    "            axes = axes.flatten()\n",
    "\n",
    "            for i, ax in enumerate(axes):\n",
    "                ax.imshow(generated_images[i])\n",
    "                ax.set_title(self.label_map[class_labels[i].numpy().item()], fontsize=16)\n",
    "                ax.axis('off')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'images/cdcgan_images/generated_img_{epoch + 1}.png')\n",
    "            plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training cDCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "LATENT_DIM = 128    \n",
    "LEARNING_RATE = 2e-4\n",
    "BETA_1 = 0.5\n",
    "LABEL_SMOOTHING = 0.1\n",
    "\n",
    "label_map = {\n",
    "    0: 'airplane',\n",
    "    1: 'automobile',\n",
    "    2: 'bird',\n",
    "    3: 'cat',\n",
    "    4: 'deer',\n",
    "    5: 'dog',\n",
    "    6: 'frog',\n",
    "    7: 'horse',\n",
    "    8: 'ship',\n",
    "    9: 'truck'\n",
    "}\n",
    "\n",
    "callbacks = [GANMonitor(LATENT_DIM, label_map)]\n",
    "\n",
    "generator = create_generator(LATENT_DIM)\n",
    "discriminator = create_discriminator()\n",
    "cdcgan = ConditionalDCGAN(generator, discriminator, latent_dim=LATENT_DIM)\n",
    "cdcgan.compile(\n",
    "    g_optimizer=Adam(learning_rate=LEARNING_RATE, beta_1=BETA_1),\n",
    "    d_optimizer=Adam(learning_rate=LEARNING_RATE, beta_1=BETA_1),\n",
    "    loss_fn=BinaryCrossentropy(label_smoothing=LABEL_SMOOTHING)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "467/467 [==============================] - 58s 103ms/step - g_loss: 2.6322 - d_loss: 0.5104 - d_acc: 0.8900\n",
      "Epoch 2/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 2.1156 - d_loss: 0.4708 - d_acc: 0.9325\n",
      "Epoch 3/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.8866 - d_loss: 0.4851 - d_acc: 0.9133\n",
      "Epoch 4/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.9830 - d_loss: 0.4800 - d_acc: 0.9169\n",
      "Epoch 5/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.9019 - d_loss: 0.4962 - d_acc: 0.8967\n",
      "Epoch 6/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.8959 - d_loss: 0.4796 - d_acc: 0.9166\n",
      "Epoch 7/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.8631 - d_loss: 0.4753 - d_acc: 0.9225\n",
      "Epoch 8/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.8357 - d_loss: 0.4785 - d_acc: 0.9199\n",
      "Epoch 9/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.7995 - d_loss: 0.4735 - d_acc: 0.9254\n",
      "Epoch 10/200\n",
      "467/467 [==============================] - ETA: 0s - g_loss: 1.8245 - d_loss: 0.4762 - d_acc: 0.9200\n",
      "\n",
      "Saving weights at epoch 10\n",
      "\n",
      "467/467 [==============================] - 50s 106ms/step - g_loss: 1.8245 - d_loss: 0.4762 - d_acc: 0.9200\n",
      "Epoch 11/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.7191 - d_loss: 0.4766 - d_acc: 0.9251\n",
      "Epoch 12/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.8254 - d_loss: 0.4719 - d_acc: 0.9294\n",
      "Epoch 13/200\n",
      "467/467 [==============================] - 44s 93ms/step - g_loss: 1.8186 - d_loss: 0.4758 - d_acc: 0.9242\n",
      "Epoch 14/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.7378 - d_loss: 0.4778 - d_acc: 0.9207\n",
      "Epoch 15/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.6640 - d_loss: 0.4906 - d_acc: 0.9040\n",
      "Epoch 16/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.6069 - d_loss: 0.5081 - d_acc: 0.8829\n",
      "Epoch 17/200\n",
      "467/467 [==============================] - 44s 93ms/step - g_loss: 1.5634 - d_loss: 0.5061 - d_acc: 0.8844\n",
      "Epoch 18/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.6193 - d_loss: 0.4994 - d_acc: 0.8916\n",
      "Epoch 19/200\n",
      "467/467 [==============================] - 44s 93ms/step - g_loss: 1.6246 - d_loss: 0.5000 - d_acc: 0.8905\n",
      "Epoch 20/200\n",
      "467/467 [==============================] - ETA: 0s - g_loss: 1.4776 - d_loss: 0.5070 - d_acc: 0.8870\n",
      "\n",
      "Saving weights at epoch 20\n",
      "\n",
      "467/467 [==============================] - 50s 106ms/step - g_loss: 1.4776 - d_loss: 0.5070 - d_acc: 0.8870\n",
      "Epoch 21/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.4753 - d_loss: 0.5123 - d_acc: 0.8770\n",
      "Epoch 22/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.4406 - d_loss: 0.5140 - d_acc: 0.8746\n",
      "Epoch 23/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.4458 - d_loss: 0.5192 - d_acc: 0.8645\n",
      "Epoch 24/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.4328 - d_loss: 0.5219 - d_acc: 0.8607\n",
      "Epoch 25/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.4096 - d_loss: 0.5222 - d_acc: 0.8619\n",
      "Epoch 26/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.3867 - d_loss: 0.5266 - d_acc: 0.8563\n",
      "Epoch 27/200\n",
      "467/467 [==============================] - 44s 95ms/step - g_loss: 1.3557 - d_loss: 0.5328 - d_acc: 0.8480\n",
      "Epoch 28/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.3155 - d_loss: 0.5337 - d_acc: 0.8442\n",
      "Epoch 29/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.3137 - d_loss: 0.5431 - d_acc: 0.8352\n",
      "Epoch 30/200\n",
      "467/467 [==============================] - ETA: 0s - g_loss: 1.3203 - d_loss: 0.5316 - d_acc: 0.8467\n",
      "\n",
      "Saving weights at epoch 30\n",
      "\n",
      "467/467 [==============================] - 50s 107ms/step - g_loss: 1.3203 - d_loss: 0.5316 - d_acc: 0.8467\n",
      "Epoch 31/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.2972 - d_loss: 0.5437 - d_acc: 0.8343\n",
      "Epoch 32/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.3041 - d_loss: 0.5398 - d_acc: 0.8388\n",
      "Epoch 33/200\n",
      "467/467 [==============================] - 44s 95ms/step - g_loss: 1.3211 - d_loss: 0.5373 - d_acc: 0.8394\n",
      "Epoch 34/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.2812 - d_loss: 0.5411 - d_acc: 0.8341\n",
      "Epoch 35/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.2396 - d_loss: 0.5435 - d_acc: 0.8324\n",
      "Epoch 36/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.2586 - d_loss: 0.5464 - d_acc: 0.8302\n",
      "Epoch 37/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.2459 - d_loss: 0.5467 - d_acc: 0.8272\n",
      "Epoch 38/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.2140 - d_loss: 0.5512 - d_acc: 0.8229\n",
      "Epoch 39/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.2141 - d_loss: 0.5501 - d_acc: 0.8225\n",
      "Epoch 40/200\n",
      "467/467 [==============================] - ETA: 0s - g_loss: 1.2134 - d_loss: 0.5574 - d_acc: 0.8162\n",
      "\n",
      "Saving weights at epoch 40\n",
      "\n",
      "467/467 [==============================] - 50s 107ms/step - g_loss: 1.2134 - d_loss: 0.5574 - d_acc: 0.8162\n",
      "Epoch 41/200\n",
      "467/467 [==============================] - 44s 95ms/step - g_loss: 1.2135 - d_loss: 0.5466 - d_acc: 0.8244\n",
      "Epoch 42/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.1953 - d_loss: 0.5596 - d_acc: 0.8145\n",
      "Epoch 43/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.1781 - d_loss: 0.5544 - d_acc: 0.8181\n",
      "Epoch 44/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.1988 - d_loss: 0.5525 - d_acc: 0.8195\n",
      "Epoch 45/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.1826 - d_loss: 0.5548 - d_acc: 0.8155\n",
      "Epoch 46/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.2075 - d_loss: 0.5579 - d_acc: 0.8113\n",
      "Epoch 47/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.1738 - d_loss: 0.5548 - d_acc: 0.8145\n",
      "Epoch 48/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.1854 - d_loss: 0.5592 - d_acc: 0.8109\n",
      "Epoch 49/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.1645 - d_loss: 0.5611 - d_acc: 0.8081\n",
      "Epoch 50/200\n",
      "467/467 [==============================] - ETA: 0s - g_loss: 1.1778 - d_loss: 0.5537 - d_acc: 0.8161\n",
      "\n",
      "Saving weights at epoch 50\n",
      "\n",
      "467/467 [==============================] - 50s 106ms/step - g_loss: 1.1778 - d_loss: 0.5537 - d_acc: 0.8161\n",
      "Epoch 51/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.1891 - d_loss: 0.5627 - d_acc: 0.8086\n",
      "Epoch 52/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.1784 - d_loss: 0.5522 - d_acc: 0.8169\n",
      "Epoch 53/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.1680 - d_loss: 0.5618 - d_acc: 0.8088\n",
      "Epoch 54/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.1890 - d_loss: 0.5573 - d_acc: 0.8124\n",
      "Epoch 55/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.1909 - d_loss: 0.5505 - d_acc: 0.8192\n",
      "Epoch 56/200\n",
      "467/467 [==============================] - 44s 95ms/step - g_loss: 1.1906 - d_loss: 0.5498 - d_acc: 0.8181\n",
      "Epoch 57/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.1938 - d_loss: 0.5534 - d_acc: 0.8178\n",
      "Epoch 58/200\n",
      "467/467 [==============================] - 44s 95ms/step - g_loss: 1.1993 - d_loss: 0.5507 - d_acc: 0.8208\n",
      "Epoch 59/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.1957 - d_loss: 0.5484 - d_acc: 0.8237\n",
      "Epoch 60/200\n",
      "467/467 [==============================] - ETA: 0s - g_loss: 1.1987 - d_loss: 0.5564 - d_acc: 0.8177\n",
      "\n",
      "Saving weights at epoch 60\n",
      "\n",
      "467/467 [==============================] - 50s 107ms/step - g_loss: 1.1987 - d_loss: 0.5564 - d_acc: 0.8177\n",
      "Epoch 61/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.2049 - d_loss: 0.5437 - d_acc: 0.8284\n",
      "Epoch 62/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.2054 - d_loss: 0.5586 - d_acc: 0.8166\n",
      "Epoch 63/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.2057 - d_loss: 0.5423 - d_acc: 0.8317\n",
      "Epoch 64/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.2112 - d_loss: 0.5503 - d_acc: 0.8254\n",
      "Epoch 65/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.2137 - d_loss: 0.5443 - d_acc: 0.8289\n",
      "Epoch 66/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.2220 - d_loss: 0.5395 - d_acc: 0.8318\n",
      "Epoch 67/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.2189 - d_loss: 0.5508 - d_acc: 0.8231\n",
      "Epoch 68/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.2342 - d_loss: 0.5520 - d_acc: 0.8236\n",
      "Epoch 69/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.2252 - d_loss: 0.5396 - d_acc: 0.8333\n",
      "Epoch 70/200\n",
      "467/467 [==============================] - ETA: 0s - g_loss: 1.2353 - d_loss: 0.5448 - d_acc: 0.8313\n",
      "\n",
      "Saving weights at epoch 70\n",
      "\n",
      "467/467 [==============================] - 50s 108ms/step - g_loss: 1.2353 - d_loss: 0.5448 - d_acc: 0.8313\n",
      "Epoch 71/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.2364 - d_loss: 0.5372 - d_acc: 0.8367\n",
      "Epoch 72/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.2440 - d_loss: 0.5484 - d_acc: 0.8270\n",
      "Epoch 73/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.2282 - d_loss: 0.5383 - d_acc: 0.8360\n",
      "Epoch 74/200\n",
      "467/467 [==============================] - 44s 95ms/step - g_loss: 1.2477 - d_loss: 0.5383 - d_acc: 0.8347\n",
      "Epoch 75/200\n",
      "467/467 [==============================] - 44s 95ms/step - g_loss: 1.2473 - d_loss: 0.5352 - d_acc: 0.8375\n",
      "Epoch 76/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.2458 - d_loss: 0.5442 - d_acc: 0.8331\n",
      "Epoch 77/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.2440 - d_loss: 0.5449 - d_acc: 0.8307\n",
      "Epoch 78/200\n",
      "467/467 [==============================] - 44s 95ms/step - g_loss: 1.2499 - d_loss: 0.5350 - d_acc: 0.8401\n",
      "Epoch 79/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.2327 - d_loss: 0.5515 - d_acc: 0.8297\n",
      "Epoch 80/200\n",
      "467/467 [==============================] - ETA: 0s - g_loss: 1.2569 - d_loss: 0.5389 - d_acc: 0.8369\n",
      "\n",
      "Saving weights at epoch 80\n",
      "\n",
      "467/467 [==============================] - 50s 106ms/step - g_loss: 1.2569 - d_loss: 0.5389 - d_acc: 0.8369\n",
      "Epoch 81/200\n",
      "467/467 [==============================] - 47s 100ms/step - g_loss: 1.2584 - d_loss: 0.5292 - d_acc: 0.8478\n",
      "Epoch 82/200\n",
      "467/467 [==============================] - 46s 98ms/step - g_loss: 1.2472 - d_loss: 0.5511 - d_acc: 0.8295\n",
      "Epoch 83/200\n",
      "467/467 [==============================] - 47s 101ms/step - g_loss: 1.2646 - d_loss: 0.5356 - d_acc: 0.8410\n",
      "Epoch 84/200\n",
      "467/467 [==============================] - 44s 95ms/step - g_loss: 1.2667 - d_loss: 0.5358 - d_acc: 0.8412\n",
      "Epoch 85/200\n",
      "467/467 [==============================] - 45s 95ms/step - g_loss: 1.2759 - d_loss: 0.5290 - d_acc: 0.8475\n",
      "Epoch 86/200\n",
      "467/467 [==============================] - 44s 95ms/step - g_loss: 1.2738 - d_loss: 0.5321 - d_acc: 0.8442\n",
      "Epoch 87/200\n",
      "467/467 [==============================] - 44s 95ms/step - g_loss: 1.2831 - d_loss: 0.5287 - d_acc: 0.8476\n",
      "Epoch 88/200\n",
      "467/467 [==============================] - 44s 95ms/step - g_loss: 1.2884 - d_loss: 0.5326 - d_acc: 0.8451\n",
      "Epoch 89/200\n",
      "467/467 [==============================] - 46s 97ms/step - g_loss: 1.2925 - d_loss: 0.5228 - d_acc: 0.8556\n",
      "Epoch 90/200\n",
      "467/467 [==============================] - ETA: 0s - g_loss: 1.2690 - d_loss: 0.5449 - d_acc: 0.8385\n",
      "\n",
      "Saving weights at epoch 90\n",
      "\n",
      "467/467 [==============================] - 51s 109ms/step - g_loss: 1.2690 - d_loss: 0.5449 - d_acc: 0.8385\n",
      "Epoch 91/200\n",
      "467/467 [==============================] - 45s 97ms/step - g_loss: 1.2955 - d_loss: 0.5334 - d_acc: 0.8467\n",
      "Epoch 92/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.2953 - d_loss: 0.5215 - d_acc: 0.8580\n",
      "Epoch 93/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.2980 - d_loss: 0.5292 - d_acc: 0.8511\n",
      "Epoch 94/200\n",
      "467/467 [==============================] - 45s 96ms/step - g_loss: 1.3104 - d_loss: 0.5244 - d_acc: 0.8564\n",
      "Epoch 95/200\n",
      "467/467 [==============================] - 46s 98ms/step - g_loss: 1.3062 - d_loss: 0.5270 - d_acc: 0.8529\n",
      "Epoch 96/200\n",
      "467/467 [==============================] - 45s 96ms/step - g_loss: 1.3147 - d_loss: 0.5200 - d_acc: 0.8599\n",
      "Epoch 97/200\n",
      "467/467 [==============================] - 45s 96ms/step - g_loss: 1.3074 - d_loss: 0.5279 - d_acc: 0.8540\n",
      "Epoch 98/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.3109 - d_loss: 0.5314 - d_acc: 0.8525\n",
      "Epoch 99/200\n",
      "467/467 [==============================] - 44s 94ms/step - g_loss: 1.3280 - d_loss: 0.5166 - d_acc: 0.8655\n",
      "Epoch 100/200\n",
      "467/467 [==============================] - ETA: 0s - g_loss: 1.3298 - d_loss: 0.5204 - d_acc: 0.8603\n",
      "\n",
      "Saving weights at epoch 100\n",
      "\n",
      "467/467 [==============================] - 50s 106ms/step - g_loss: 1.3298 - d_loss: 0.5204 - d_acc: 0.8603\n",
      "Epoch 101/200\n",
      "467/467 [==============================] - 45s 97ms/step - g_loss: 1.3433 - d_loss: 0.5137 - d_acc: 0.8682\n",
      "Epoch 102/200\n",
      "467/467 [==============================] - 45s 96ms/step - g_loss: 1.3174 - d_loss: 0.5350 - d_acc: 0.8500\n",
      "Epoch 103/200\n",
      "138/467 [=======>......................] - ETA: 33s - g_loss: 1.3305 - d_loss: 0.5127 - d_acc: 0.8713"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:1\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Timothy Chia\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Timothy Chia\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Timothy Chia\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Timothy Chia\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Timothy Chia\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Timothy Chia\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Timothy Chia\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Timothy Chia\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Timothy Chia\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = cdcgan.fit(dataset, epochs=EPOCHS, callbacks=callbacks, use_multiprocessing=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(history.history['d_loss'], label='disc_loss')\n",
    "plt.plot(history.history['g_loss'], label='gen_loss')\n",
    "\n",
    "plt.xlabel('Epochs', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(history.history['d_acc'], label='disc_acc')\n",
    "\n",
    "plt.xlabel('Epochs', fontsize=14)\n",
    "plt.ylabel('Accuracy', fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vectors = tf.random.normal(shape=(100, LATENT_DIM))\n",
    "class_labels = tf.reshape(tf.range(10), shape=(10, 1))\n",
    "class_labels = tf.tile(class_labels, multiples=(1, 10))\n",
    "class_labels = tf.reshape(class_labels, shape=(100, 1))\n",
    "\n",
    "generated_images = cdcgan.generator([latent_vectors, class_labels], training=False)\n",
    "generated_images = (generated_images + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(10, 10, figsize=(20, 20))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(generated_images[i], cmap='gray')\n",
    "    ax.set_title(label_map[class_labels[i].numpy().item()], fontsize=18)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Model and Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # export dcgan loss and acc results\n",
    "# if not os.path.exists('performance'):\n",
    "#     os.makedirs('performance')\n",
    "\n",
    "# cdcgan_perf = dict(\n",
    "#     g_loss=history.history['g_loss'],\n",
    "#     d_loss=history.history['d_loss'],\n",
    "#     d_acc=history.history['d_acc'],\n",
    "# )\n",
    "\n",
    "# with open('performance/cdcgan_perf.pickle', 'wb') as f:\n",
    "#     pickle.dump(cdcgan_perf, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open('performance/cdcgan_perf.pickle', 'rb') as f:\n",
    "#     unserialized_data = pickle.load(f)\n",
    "\n",
    "# assert cdcgan_perf == unserialized_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Radford, A., Metz, L. and Chintala, S. (2016) Unsupervised representation learning with deep convolutional generative Adversarial Networks, arXiv.org. Available at: https://arxiv.org/abs/1511.06434 (Accessed: January 8, 2023). \n",
    "\n",
    "[2] Mirza, M. and Osindero, S. (2014) Conditional generative adversarial nets, arXiv.org. Available at: https://arxiv.org/abs/1411.1784 (Accessed: January 8, 2023). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "809cfabedfec5505d58d2ff1a7e8d59224e89d6ac7eab6869e246e57cb6db813"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Deep Convolutional Generative Adversarial Network (cDCGAN)\n",
    "\n",
    "This notebook will contain my implmentation of DCGAN from the paper [1] conditioning the generator and discriminator models  with label information, a concept introduced in [2]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_addons\n",
      "  Downloading tensorflow_addons-0.19.0-cp38-cp38-win_amd64.whl (742 kB)\n",
      "     -------------------------------------- 742.4/742.4 kB 2.1 MB/s eta 0:00:00\n",
      "Collecting typeguard>=2.7\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\p2106911\\.conda\\envs\\gpu_env\\lib\\site-packages (from tensorflow_addons) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\p2106911\\.conda\\envs\\gpu_env\\lib\\site-packages (from packaging->tensorflow_addons) (3.0.9)\n",
      "Installing collected packages: typeguard, tensorflow_addons\n",
      "Successfully installed tensorflow_addons-0.19.0 typeguard-2.13.3\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorflow_addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from IPython import display\n",
    "from tensorflow.data import Dataset\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Conv2DTranspose, Embedding, Reshape, Flatten, Dropout, BatchNormalization, ReLU, LeakyReLU, MaxPooling2D, Concatenate\n",
    "# from tensorflow_addons.layers import InstanceNormalization\n",
    "\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from utils import FrechetInceptionDistance\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.dpi': 120})\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set gpu memory growth\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.uint8, name=None))\n"
     ]
    }
   ],
   "source": [
    "FILE_PATH = 'data\\cifar10.tfrecords'\n",
    "dataset = Dataset.load(FILE_PATH)\n",
    "print(dataset.element_spec)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator(latent_dim):\n",
    "    # foundation for label embeedded input\n",
    "    label_input = Input(shape=(1,), name='label_input')\n",
    "    label_embedding = Embedding(10, 10, name='label_embedding')(label_input)\n",
    "    \n",
    "    # linear activation\n",
    "    label_embedding = Dense(4 * 4, name='label_dense')(label_embedding)\n",
    "\n",
    "    # reshape to additional channel\n",
    "    label_embedding = Reshape((4, 4, 1), name='label_reshape')(label_embedding)\n",
    "    assert label_embedding.shape == (None, 4, 4, 1)\n",
    "\n",
    "    # foundation for 4x4 image input\n",
    "    noise_input = Input(shape=(latent_dim,), name='noise_input')\n",
    "    noise_dense = Dense(4 * 4 * 128, name='noise_dense')(noise_input)\n",
    "    noise_dense = ReLU(name='noise_relu')(noise_dense)\n",
    "    noise_reshape = Reshape((4, 4, 128), name='noise_reshape')(noise_dense)\n",
    "    assert noise_reshape.shape == (None, 4, 4, 128)\n",
    "\n",
    "    # concatenate label embedding and image to produce 129-channel output\n",
    "    concat = keras.layers.Concatenate(name='concatenate')([noise_reshape, label_embedding])\n",
    "    assert concat.shape == (None, 4, 4, 129)\n",
    "\n",
    "    # upsample to 8x8\n",
    "    conv1 = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', name='conv1')(concat)\n",
    "    assert conv1.shape == (None, 8, 8, 128)\n",
    "    # conv1 = InstanceNormalization(name='conv1_norm')(conv1)\n",
    "    conv1 = ReLU(name='conv1_relu')(conv1)\n",
    "\n",
    "    # upsample to 16x16\n",
    "    conv2 = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', name='conv2')(conv1)\n",
    "    assert conv2.shape == (None, 16, 16, 128)\n",
    "    # conv2 = InstanceNormalization(name='conv2_norm')(conv2)\n",
    "    conv2 = ReLU(name='conv2_relu')(conv2)\n",
    "\n",
    "    # upsample to 32x32\n",
    "    conv3 = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', name='conv3')(conv2)\n",
    "    assert conv3.shape == (None, 32, 32, 128)\n",
    "    # conv3 = InstanceNormalization(name='conv3_norm')(conv3)\n",
    "    conv3 = ReLU(name='conv3_relu')(conv3)\n",
    "    \n",
    "    # output 32x32x3\n",
    "    output = Conv2D(3, (3, 3), activation='tanh', padding='same', name='output')(conv3)\n",
    "    assert output.shape == (None, 32, 32, 3)\n",
    "\n",
    "    model = Model(inputs=[noise_input, label_input], outputs=output, name='generator')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " noise_input (InputLayer)       [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " label_input (InputLayer)       [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " noise_dense (Dense)            (None, 2048)         264192      ['noise_input[0][0]']            \n",
      "                                                                                                  \n",
      " label_embedding (Embedding)    (None, 1, 10)        100         ['label_input[0][0]']            \n",
      "                                                                                                  \n",
      " noise_relu (ReLU)              (None, 2048)         0           ['noise_dense[0][0]']            \n",
      "                                                                                                  \n",
      " label_dense (Dense)            (None, 1, 16)        176         ['label_embedding[0][0]']        \n",
      "                                                                                                  \n",
      " noise_reshape (Reshape)        (None, 4, 4, 128)    0           ['noise_relu[0][0]']             \n",
      "                                                                                                  \n",
      " label_reshape (Reshape)        (None, 4, 4, 1)      0           ['label_dense[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 4, 4, 129)    0           ['noise_reshape[0][0]',          \n",
      "                                                                  'label_reshape[0][0]']          \n",
      "                                                                                                  \n",
      " conv1 (Conv2DTranspose)        (None, 8, 8, 128)    264320      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv1_norm (InstanceNormalizat  (None, 8, 8, 128)   256         ['conv1[0][0]']                  \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv1_relu (ReLU)              (None, 8, 8, 128)    0           ['conv1_norm[0][0]']             \n",
      "                                                                                                  \n",
      " conv2 (Conv2DTranspose)        (None, 16, 16, 128)  262272      ['conv1_relu[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_norm (InstanceNormalizat  (None, 16, 16, 128)  256        ['conv2[0][0]']                  \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_relu (ReLU)              (None, 16, 16, 128)  0           ['conv2_norm[0][0]']             \n",
      "                                                                                                  \n",
      " conv3 (Conv2DTranspose)        (None, 32, 32, 128)  262272      ['conv2_relu[0][0]']             \n",
      "                                                                                                  \n",
      " conv3_norm (InstanceNormalizat  (None, 32, 32, 128)  256        ['conv3[0][0]']                  \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_relu (ReLU)              (None, 32, 32, 128)  0           ['conv3_norm[0][0]']             \n",
      "                                                                                                  \n",
      " output (Conv2D)                (None, 32, 32, 3)    3459        ['conv3_relu[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,057,559\n",
      "Trainable params: 1,057,559\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "create_generator(latent_dim=128).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize generator\n",
    "# plot_model(generator, show_shapes=True, to_file='images\\model_architecture\\Conditional_DCGAN\\generator.png')\n",
    "# generator_img = mpimg.imread('images\\model_architecture\\Conditional_DCGAN\\generator.png')\n",
    "\n",
    "# plt.figure(figsize=(20, 20))\n",
    "# imgplot = plt.imshow(generator_img)\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discriminator():\n",
    "    # foundation for label embeedded input\n",
    "    label_input = Input(shape=(1,), name='label_input')\n",
    "    label_embedding = Embedding(10, 10, name='label_embedding')(label_input)\n",
    "    \n",
    "    # linear activation\n",
    "    label_embedding = Dense(32 * 32, name='label_dense')(label_embedding)\n",
    "    \n",
    "    # reshape to additional channel\n",
    "    label_embedding = Reshape((32, 32, 1), name='label_reshape')(label_embedding)\n",
    "    assert label_embedding.shape == (None, 32, 32, 1)\n",
    "\n",
    "    # foundation for 32x32 image input\n",
    "    image_input = Input(shape=(32, 32, 3), name='image_input')\n",
    "\n",
    "    # concatenate label embedding and image to produce 129-channel input\n",
    "    concat = keras.layers.Concatenate(name='concatenate')([image_input, label_embedding])\n",
    "    assert concat.shape == (None, 32, 32, 4)\n",
    "\n",
    "    # downsample to 16x16\n",
    "    conv1 = Conv2D(128, kernel_size=3, strides=2, padding='same', name='conv1')(concat)\n",
    "    assert conv1.shape == (None, 16, 16, 128)\n",
    "    # conv1 = InstanceNormalization(name='conv1_norm')(conv1)\n",
    "    conv1 = LeakyReLU(alpha=0.2, name='conv1_leaky_relu')(conv1)\n",
    "    \n",
    "    # downsample to 8x8\n",
    "    conv2 = Conv2D(128, kernel_size=3, strides=2, padding='same', name='conv2')(conv1)\n",
    "    assert conv2.shape == (None, 8, 8, 128)\n",
    "    # conv2 = InstanceNormalization(name='conv2_norm')(conv2)\n",
    "    conv2 = LeakyReLU(alpha=0.2, name='conv2_leaky_relu')(conv2)\n",
    "    \n",
    "    # downsample to 4x4\n",
    "    conv3 = Conv2D(128, kernel_size=3, strides=2, padding='same', name='conv3')(conv2)\n",
    "    assert conv3.shape == (None, 4, 4, 128)\n",
    "    # conv3 = InstanceNormalization(name='conv3_norm')(conv3)\n",
    "    conv3 = LeakyReLU(alpha=0.2, name='conv3_leaky_relu')(conv3)\n",
    "\n",
    "    # flatten feature maps\n",
    "    flat = Flatten(name='flatten')(conv3)\n",
    "    \n",
    "    output = Dense(units=1, activation='sigmoid', name='output')(flat)\n",
    "\n",
    "    model = Model(inputs=[image_input, label_input], outputs=output, name='discriminator')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " label_input (InputLayer)       [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " label_embedding (Embedding)    (None, 1, 10)        100         ['label_input[0][0]']            \n",
      "                                                                                                  \n",
      " label_dense (Dense)            (None, 1, 1024)      11264       ['label_embedding[0][0]']        \n",
      "                                                                                                  \n",
      " image_input (InputLayer)       [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " label_reshape (Reshape)        (None, 32, 32, 1)    0           ['label_dense[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 32, 32, 4)    0           ['image_input[0][0]',            \n",
      "                                                                  'label_reshape[0][0]']          \n",
      "                                                                                                  \n",
      " conv1 (Conv2D)                 (None, 16, 16, 128)  4736        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv1_norm (InstanceNormalizat  (None, 16, 16, 128)  256        ['conv1[0][0]']                  \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv1_leaky_relu (LeakyReLU)   (None, 16, 16, 128)  0           ['conv1_norm[0][0]']             \n",
      "                                                                                                  \n",
      " conv2 (Conv2D)                 (None, 8, 8, 128)    147584      ['conv1_leaky_relu[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_norm (InstanceNormalizat  (None, 8, 8, 128)   256         ['conv2[0][0]']                  \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_leaky_relu (LeakyReLU)   (None, 8, 8, 128)    0           ['conv2_norm[0][0]']             \n",
      "                                                                                                  \n",
      " conv3 (Conv2D)                 (None, 4, 4, 128)    147584      ['conv2_leaky_relu[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_norm (InstanceNormalizat  (None, 4, 4, 128)   256         ['conv3[0][0]']                  \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_leaky_relu (LeakyReLU)   (None, 4, 4, 128)    0           ['conv3_norm[0][0]']             \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2048)         0           ['conv3_leaky_relu[0][0]']       \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            2049        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 314,085\n",
      "Trainable params: 314,085\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "create_discriminator().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize discriminator\n",
    "# plot_model(discriminator, show_shapes=True, to_file='images\\model_architecture\\Conditional_DCGAN\\discriminator.png')\n",
    "# discriminator_img = mpimg.imread('images\\model_architecture\\Conditional_DCGAN\\discriminator.png')\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# imgplot = plt.imshow(discriminator_img)\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining cDCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalDCGAN(Model):\n",
    "    def __init__(self, generator, discriminator, latent_dim):\n",
    "        super(ConditionalDCGAN, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(ConditionalDCGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.g_loss_metric = keras.metrics.Mean(name='g_loss')\n",
    "        self.d_loss_metric = keras.metrics.Mean(name='d_loss')\n",
    "        self.d_acc_metric = keras.metrics.BinaryAccuracy(name='d_acc')\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.g_loss_metric, self.d_loss_metric, self.d_acc_metric]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        real_images, class_labels = data\n",
    "        class_labels = tf.cast(class_labels, 'int32')\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "\n",
    "        # train discriminator\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_class_labels = tf.random.uniform(shape=(batch_size, 1), minval=0, maxval=10, dtype='int32')\n",
    "        generated_images = self.generator([random_latent_vectors, random_class_labels], training=False)\n",
    "\n",
    "        # combine real and generated images as well as real and generated labels\n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "        combined_class_labels = tf.concat([random_class_labels, class_labels], axis=0)\n",
    "\n",
    "        fake_labels = tf.zeros((batch_size, 1))  # (batch_size, 1)\n",
    "        real_labels = tf.ones((batch_size, 1))  # (batch_size, 1)\n",
    "        combined_labels = tf.concat([fake_labels, real_labels], axis=0)  # (2*batch_size, 1)\n",
    "\n",
    "        # train the discriminator\n",
    "        with tf.GradientTape() as disc_tape:\n",
    "            pred_on_combined = self.discriminator([combined_images, combined_class_labels], training=True)\n",
    "            d_loss = self.loss_fn(combined_labels, pred_on_combined)  # log(D(x)) + log(1 - D(G(z))\n",
    "        \n",
    "        disc_grads = disc_tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "        self.d_optimizer.apply_gradients(zip(disc_grads, self.discriminator.trainable_variables))\n",
    "\n",
    "        # train the generator\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_class_labels = tf.random.uniform(shape=(batch_size, 1), minval=0, maxval=10, dtype='int32')\n",
    "        misleading_labels = tf.ones((batch_size, 1))\n",
    "\n",
    "        with tf.GradientTape() as gen_tape:\n",
    "            pred_on_fake = self.discriminator([self.generator([random_latent_vectors, random_class_labels], training=True), random_class_labels], training=False)\n",
    "            g_loss = self.loss_fn(misleading_labels, pred_on_fake)  # maximize log(D(G(z))) = minimize -log(1 - D(G(z)))\n",
    "        \n",
    "        gen_grads = gen_tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        self.g_optimizer.apply_gradients(zip(gen_grads, self.generator.trainable_variables))\n",
    "\n",
    "        # update metrics\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        self.d_acc_metric.update_state(combined_labels, pred_on_combined)\n",
    "\n",
    "        return {\n",
    "            'g_loss': self.g_loss_metric.result(), \n",
    "            'd_loss': self.d_loss_metric.result(),\n",
    "            'd_acc': self.d_acc_metric.result()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANMonitor(Callback):\n",
    "    def __init__(self, latent_dim, label_map):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.label_map = label_map\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # plot 100 generated images and save weights every 10 epochs\n",
    "        latent_vectors = tf.random.normal(shape=(100, self.latent_dim))\n",
    "        class_labels = tf.reshape(tf.range(10), shape=(10, 1))\n",
    "        class_labels = tf.tile(class_labels, multiples=(1, 10))\n",
    "        class_labels = tf.reshape(class_labels, shape=(100, 1))\n",
    "\n",
    "        generated_images = self.model.generator([latent_vectors, class_labels], training=False)\n",
    "        generated_images = (generated_images + 1) / 2\n",
    "\n",
    "        if not os.path.exists('assets/cdcgan'):\n",
    "            os.makedirs('assets/cdcgan')\n",
    "\n",
    "        if not os.path.exists('images/cdcgan_images'):\n",
    "            os.makedirs('images/cdcgan_images')\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            if not os.path.exists(f'assets/cdcgan/epoch_{epoch + 1}'):\n",
    "                os.makedirs(f'assets/cdcgan/epoch_{epoch + 1}')\n",
    "                self.model.generator.save_weights(f'assets/cdcgan/epoch_{epoch + 1}/generator_weights_epoch_{epoch + 1}.h5')\n",
    "                self.model.discriminator.save_weights(f'assets/cdcgan/epoch_{epoch + 1}/discriminator_weights_epoch_{epoch + 1}.h5')\n",
    "                print(f'\\n\\nSaving weights at epoch {epoch + 1}\\n')\n",
    "\n",
    "            fig, axes = plt.subplots(10, 10, figsize=(20, 20))\n",
    "            axes = axes.flatten()\n",
    "\n",
    "            for i, ax in enumerate(axes):\n",
    "                ax.imshow(generated_images[i])\n",
    "                ax.set_title(self.label_map[class_labels[i].numpy().item()], fontsize=16)\n",
    "                ax.axis('off')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'images/cdcgan_images/generated_img_{epoch + 1}.png')\n",
    "            plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training cDCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "LATENT_DIM = 128    \n",
    "LEARNING_RATE = 2e-4\n",
    "BETA_1 = 0.5\n",
    "LABEL_SMOOTHING = 0.25\n",
    "\n",
    "label_map = {\n",
    "    0: 'airplane',\n",
    "    1: 'automobile',\n",
    "    2: 'bird',\n",
    "    3: 'cat',\n",
    "    4: 'deer',\n",
    "    5: 'dog',\n",
    "    6: 'frog',\n",
    "    7: 'horse',\n",
    "    8: 'ship',\n",
    "    9: 'truck'\n",
    "}\n",
    "\n",
    "callbacks = [GANMonitor(LATENT_DIM, label_map)]\n",
    "\n",
    "generator = create_generator(LATENT_DIM)\n",
    "discriminator = create_discriminator()\n",
    "cdcgan = ConditionalDCGAN(generator, discriminator, latent_dim=LATENT_DIM)\n",
    "cdcgan.compile(\n",
    "    g_optimizer=Adam(learning_rate=LEARNING_RATE, beta_1=BETA_1),\n",
    "    d_optimizer=Adam(learning_rate=LEARNING_RATE, beta_1=BETA_1),\n",
    "    loss_fn=BinaryCrossentropy(label_smoothing=LABEL_SMOOTHING)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "467/467 [==============================] - 38s 56ms/step - g_loss: 3.5206 - d_loss: 0.3710 - d_acc: 0.9041\n",
      "Epoch 2/200\n",
      "467/467 [==============================] - 25s 53ms/step - g_loss: 2.9614 - d_loss: 0.3594 - d_acc: 0.9206\n",
      "Epoch 3/200\n",
      "467/467 [==============================] - 24s 50ms/step - g_loss: 2.6541 - d_loss: 0.3939 - d_acc: 0.8944\n",
      "Epoch 4/200\n",
      "467/467 [==============================] - 24s 52ms/step - g_loss: 2.6879 - d_loss: 0.3913 - d_acc: 0.8917\n",
      "Epoch 5/200\n",
      "467/467 [==============================] - 25s 54ms/step - g_loss: 2.6360 - d_loss: 0.3661 - d_acc: 0.9144\n",
      "Epoch 6/200\n",
      "467/467 [==============================] - 25s 54ms/step - g_loss: 2.8062 - d_loss: 0.3509 - d_acc: 0.9233\n",
      "Epoch 7/200\n",
      "467/467 [==============================] - 25s 53ms/step - g_loss: 2.7665 - d_loss: 0.3377 - d_acc: 0.9335\n",
      "Epoch 8/200\n",
      "467/467 [==============================] - 25s 53ms/step - g_loss: 2.7720 - d_loss: 0.3428 - d_acc: 0.9290\n",
      "Epoch 9/200\n",
      "467/467 [==============================] - 25s 53ms/step - g_loss: 2.7774 - d_loss: 0.3279 - d_acc: 0.9396\n",
      "Epoch 10/200\n",
      "466/467 [============================>.] - ETA: 0s - g_loss: 2.8312 - d_loss: 0.3385 - d_acc: 0.9302\n",
      "\n",
      "Saving weights at epoch 10\n",
      "\n",
      "467/467 [==============================] - 31s 67ms/step - g_loss: 2.8308 - d_loss: 0.3385 - d_acc: 0.9302\n",
      "Epoch 11/200\n",
      "467/467 [==============================] - 25s 54ms/step - g_loss: 2.7934 - d_loss: 0.3325 - d_acc: 0.9347\n",
      "Epoch 12/200\n",
      "467/467 [==============================] - 28s 60ms/step - g_loss: 2.8811 - d_loss: 0.3362 - d_acc: 0.9313\n",
      "Epoch 13/200\n",
      "467/467 [==============================] - 29s 63ms/step - g_loss: 2.6988 - d_loss: 0.3424 - d_acc: 0.9270\n",
      "Epoch 14/200\n",
      "467/467 [==============================] - 55s 118ms/step - g_loss: 2.7226 - d_loss: 0.3511 - d_acc: 0.9207\n",
      "Epoch 15/200\n",
      "467/467 [==============================] - 53s 114ms/step - g_loss: 2.5259 - d_loss: 0.3533 - d_acc: 0.9211\n",
      "Epoch 16/200\n",
      "467/467 [==============================] - 51s 110ms/step - g_loss: 2.3615 - d_loss: 0.3737 - d_acc: 0.9054\n",
      "Epoch 17/200\n",
      "467/467 [==============================] - 49s 106ms/step - g_loss: 2.2549 - d_loss: 0.3930 - d_acc: 0.8883\n",
      "Epoch 18/200\n",
      "467/467 [==============================] - 36s 77ms/step - g_loss: 2.1492 - d_loss: 0.4079 - d_acc: 0.8787\n",
      "Epoch 19/200\n",
      "467/467 [==============================] - 25s 54ms/step - g_loss: 2.1591 - d_loss: 0.4012 - d_acc: 0.8813\n",
      "Epoch 20/200\n",
      "467/467 [==============================] - ETA: 0s - g_loss: 2.1342 - d_loss: 0.4108 - d_acc: 0.8749\n",
      "\n",
      "Saving weights at epoch 20\n",
      "\n",
      "467/467 [==============================] - 42s 90ms/step - g_loss: 2.1342 - d_loss: 0.4108 - d_acc: 0.8749\n",
      "Epoch 21/200\n",
      "467/467 [==============================] - 52s 111ms/step - g_loss: 2.0617 - d_loss: 0.4045 - d_acc: 0.8781\n",
      "Epoch 22/200\n",
      "467/467 [==============================] - 52s 112ms/step - g_loss: 1.9987 - d_loss: 0.4140 - d_acc: 0.8702\n",
      "Epoch 23/200\n",
      "467/467 [==============================] - 52s 111ms/step - g_loss: 1.9469 - d_loss: 0.4252 - d_acc: 0.8636\n",
      "Epoch 24/200\n",
      "467/467 [==============================] - 53s 114ms/step - g_loss: 2.1621 - d_loss: 0.4070 - d_acc: 0.8731\n",
      "Epoch 25/200\n",
      "467/467 [==============================] - 51s 110ms/step - g_loss: 1.7899 - d_loss: 0.4213 - d_acc: 0.8641\n",
      "Epoch 26/200\n",
      "467/467 [==============================] - 51s 109ms/step - g_loss: 1.9069 - d_loss: 0.4284 - d_acc: 0.8593\n",
      "Epoch 27/200\n",
      "467/467 [==============================] - 50s 106ms/step - g_loss: 1.8258 - d_loss: 0.4343 - d_acc: 0.8540\n",
      "Epoch 28/200\n",
      "467/467 [==============================] - 49s 106ms/step - g_loss: 1.7591 - d_loss: 0.4492 - d_acc: 0.8438\n",
      "Epoch 29/200\n",
      "467/467 [==============================] - 48s 103ms/step - g_loss: 1.7223 - d_loss: 0.4471 - d_acc: 0.8424\n",
      "Epoch 30/200\n",
      "467/467 [==============================] - ETA: 0s - g_loss: 1.7273 - d_loss: 0.4557 - d_acc: 0.8353\n",
      "\n",
      "Saving weights at epoch 30\n",
      "\n",
      "467/467 [==============================] - 56s 120ms/step - g_loss: 1.7273 - d_loss: 0.4557 - d_acc: 0.8353\n",
      "Epoch 31/200\n",
      "467/467 [==============================] - 51s 109ms/step - g_loss: 1.7649 - d_loss: 0.4453 - d_acc: 0.8416\n",
      "Epoch 32/200\n",
      "467/467 [==============================] - 52s 111ms/step - g_loss: 1.6878 - d_loss: 0.4506 - d_acc: 0.8362\n",
      "Epoch 33/200\n",
      "467/467 [==============================] - 51s 109ms/step - g_loss: 1.7025 - d_loss: 0.4683 - d_acc: 0.8297\n",
      "Epoch 34/200\n",
      "467/467 [==============================] - 51s 108ms/step - g_loss: 1.6421 - d_loss: 0.4521 - d_acc: 0.8359\n",
      "Epoch 35/200\n",
      "467/467 [==============================] - 51s 110ms/step - g_loss: 1.6551 - d_loss: 0.4645 - d_acc: 0.8303\n",
      "Epoch 36/200\n",
      "467/467 [==============================] - 52s 112ms/step - g_loss: 1.6179 - d_loss: 0.4554 - d_acc: 0.8335\n",
      "Epoch 37/200\n",
      "467/467 [==============================] - 53s 114ms/step - g_loss: 1.6273 - d_loss: 0.4569 - d_acc: 0.8314\n",
      "Epoch 38/200\n",
      "467/467 [==============================] - 52s 111ms/step - g_loss: 1.6018 - d_loss: 0.4676 - d_acc: 0.8229\n",
      "Epoch 39/200\n",
      "467/467 [==============================] - 51s 109ms/step - g_loss: 1.5619 - d_loss: 0.4664 - d_acc: 0.8265\n",
      "Epoch 40/200\n",
      "467/467 [==============================] - ETA: 0s - g_loss: 1.5715 - d_loss: 0.4825 - d_acc: 0.8130\n",
      "\n",
      "Saving weights at epoch 40\n",
      "\n",
      "467/467 [==============================] - 57s 123ms/step - g_loss: 1.5715 - d_loss: 0.4825 - d_acc: 0.8130\n",
      "Epoch 41/200\n",
      "467/467 [==============================] - 51s 110ms/step - g_loss: 1.5761 - d_loss: 0.4750 - d_acc: 0.8178\n",
      "Epoch 42/200\n",
      "467/467 [==============================] - 51s 110ms/step - g_loss: 1.6032 - d_loss: 0.4607 - d_acc: 0.8286\n",
      "Epoch 43/200\n",
      "467/467 [==============================] - 53s 114ms/step - g_loss: 1.5693 - d_loss: 0.4663 - d_acc: 0.8253\n",
      "Epoch 44/200\n",
      "467/467 [==============================] - 52s 112ms/step - g_loss: 1.5522 - d_loss: 0.4669 - d_acc: 0.8212\n",
      "Epoch 45/200\n",
      "467/467 [==============================] - 53s 113ms/step - g_loss: 1.5479 - d_loss: 0.4724 - d_acc: 0.8184\n",
      "Epoch 46/200\n",
      "467/467 [==============================] - 51s 109ms/step - g_loss: 1.5484 - d_loss: 0.4639 - d_acc: 0.8239\n",
      "Epoch 47/200\n",
      "467/467 [==============================] - 50s 108ms/step - g_loss: 1.5369 - d_loss: 0.4746 - d_acc: 0.8191\n",
      "Epoch 48/200\n",
      "467/467 [==============================] - 50s 107ms/step - g_loss: 1.5180 - d_loss: 0.4829 - d_acc: 0.8130\n",
      "Epoch 49/200\n",
      "467/467 [==============================] - 50s 108ms/step - g_loss: 1.5207 - d_loss: 0.4829 - d_acc: 0.8126\n",
      "Epoch 50/200\n",
      "467/467 [==============================] - ETA: 0s - g_loss: 1.5419 - d_loss: 0.4750 - d_acc: 0.8173\n",
      "\n",
      "Saving weights at epoch 50\n",
      "\n",
      "467/467 [==============================] - 58s 123ms/step - g_loss: 1.5419 - d_loss: 0.4750 - d_acc: 0.8173\n",
      "Epoch 51/200\n",
      "467/467 [==============================] - 52s 111ms/step - g_loss: 1.5239 - d_loss: 0.4774 - d_acc: 0.8157\n",
      "Epoch 52/200\n",
      "467/467 [==============================] - 32s 69ms/step - g_loss: 1.5274 - d_loss: 0.4687 - d_acc: 0.8199\n",
      "Epoch 53/200\n",
      "467/467 [==============================] - 25s 54ms/step - g_loss: 1.5274 - d_loss: 0.4734 - d_acc: 0.8176\n",
      "Epoch 54/200\n",
      "467/467 [==============================] - 25s 53ms/step - g_loss: 1.5324 - d_loss: 0.4843 - d_acc: 0.8112\n",
      "Epoch 55/200\n",
      "467/467 [==============================] - 48s 102ms/step - g_loss: 1.5240 - d_loss: 0.4654 - d_acc: 0.8225\n",
      "Epoch 56/200\n",
      "467/467 [==============================] - 52s 112ms/step - g_loss: 1.5273 - d_loss: 0.4871 - d_acc: 0.8092\n",
      "Epoch 57/200\n",
      "467/467 [==============================] - 52s 112ms/step - g_loss: 1.5111 - d_loss: 0.4732 - d_acc: 0.8210\n",
      "Epoch 58/200\n",
      "467/467 [==============================] - 53s 113ms/step - g_loss: 1.5463 - d_loss: 0.4673 - d_acc: 0.8230\n",
      "Epoch 59/200\n",
      "467/467 [==============================] - 52s 112ms/step - g_loss: 1.5315 - d_loss: 0.4768 - d_acc: 0.8177\n",
      "Epoch 60/200\n",
      "467/467 [==============================] - ETA: 0s - g_loss: 1.5473 - d_loss: 0.4717 - d_acc: 0.8224\n",
      "\n",
      "Saving weights at epoch 60\n",
      "\n",
      "467/467 [==============================] - 59s 127ms/step - g_loss: 1.5473 - d_loss: 0.4717 - d_acc: 0.8224\n",
      "Epoch 61/200\n",
      "467/467 [==============================] - 51s 109ms/step - g_loss: 1.5548 - d_loss: 0.4600 - d_acc: 0.8279\n",
      "Epoch 62/200\n",
      "467/467 [==============================] - 51s 109ms/step - g_loss: 1.5609 - d_loss: 0.4668 - d_acc: 0.8242\n",
      "Epoch 63/200\n",
      "467/467 [==============================] - 51s 110ms/step - g_loss: 1.5896 - d_loss: 0.4584 - d_acc: 0.8275\n",
      "Epoch 64/200\n",
      "467/467 [==============================] - 51s 109ms/step - g_loss: 1.5721 - d_loss: 0.4599 - d_acc: 0.8290\n",
      "Epoch 65/200\n",
      "467/467 [==============================] - 51s 110ms/step - g_loss: 1.5763 - d_loss: 0.4638 - d_acc: 0.8272\n",
      "Epoch 66/200\n",
      "467/467 [==============================] - 50s 108ms/step - g_loss: 1.6084 - d_loss: 0.4580 - d_acc: 0.8302\n",
      "Epoch 67/200\n",
      "467/467 [==============================] - 51s 109ms/step - g_loss: 1.5944 - d_loss: 0.4645 - d_acc: 0.8299\n",
      "Epoch 68/200\n",
      "467/467 [==============================] - 51s 109ms/step - g_loss: 1.5906 - d_loss: 0.4506 - d_acc: 0.8353\n",
      "Epoch 69/200\n",
      "467/467 [==============================] - 51s 109ms/step - g_loss: 1.6194 - d_loss: 0.4488 - d_acc: 0.8362\n",
      "Epoch 70/200\n",
      "467/467 [==============================] - ETA: 0s - g_loss: 1.5893 - d_loss: 0.4660 - d_acc: 0.8279\n",
      "\n",
      "Saving weights at epoch 70\n",
      "\n",
      "467/467 [==============================] - 57s 123ms/step - g_loss: 1.5893 - d_loss: 0.4660 - d_acc: 0.8279\n",
      "Epoch 71/200\n",
      "467/467 [==============================] - 52s 110ms/step - g_loss: 1.6076 - d_loss: 0.4621 - d_acc: 0.8289\n",
      "Epoch 72/200\n",
      "467/467 [==============================] - 54s 116ms/step - g_loss: 1.6218 - d_loss: 0.4450 - d_acc: 0.8394\n",
      "Epoch 73/200\n",
      "467/467 [==============================] - 53s 114ms/step - g_loss: 1.6270 - d_loss: 0.4597 - d_acc: 0.8296\n",
      "Epoch 74/200\n",
      "467/467 [==============================] - 53s 114ms/step - g_loss: 1.6105 - d_loss: 0.4441 - d_acc: 0.8409\n",
      "Epoch 75/200\n",
      "467/467 [==============================] - 52s 112ms/step - g_loss: 1.6174 - d_loss: 0.4589 - d_acc: 0.8322\n",
      "Epoch 76/200\n",
      "467/467 [==============================] - 53s 113ms/step - g_loss: 1.6233 - d_loss: 0.4526 - d_acc: 0.8363\n",
      "Epoch 77/200\n",
      "467/467 [==============================] - 51s 110ms/step - g_loss: 1.6270 - d_loss: 0.4503 - d_acc: 0.8375\n",
      "Epoch 78/200\n",
      "467/467 [==============================] - 52s 112ms/step - g_loss: 1.6183 - d_loss: 0.4602 - d_acc: 0.8332\n",
      "Epoch 79/200\n",
      "467/467 [==============================] - 51s 110ms/step - g_loss: 1.6230 - d_loss: 0.4565 - d_acc: 0.8353\n",
      "Epoch 80/200\n",
      "467/467 [==============================] - ETA: 0s - g_loss: 1.6378 - d_loss: 0.4392 - d_acc: 0.8447\n",
      "\n",
      "Saving weights at epoch 80\n",
      "\n",
      "467/467 [==============================] - 57s 123ms/step - g_loss: 1.6378 - d_loss: 0.4392 - d_acc: 0.8447\n",
      "Epoch 81/200\n",
      "467/467 [==============================] - 51s 109ms/step - g_loss: 1.6344 - d_loss: 0.4598 - d_acc: 0.8313\n",
      "Epoch 82/200\n",
      "467/467 [==============================] - 51s 110ms/step - g_loss: 1.6641 - d_loss: 0.4448 - d_acc: 0.8405\n",
      "Epoch 83/200\n",
      "467/467 [==============================] - 52s 111ms/step - g_loss: 1.6598 - d_loss: 0.4399 - d_acc: 0.8440\n",
      "Epoch 84/200\n",
      "467/467 [==============================] - 52s 111ms/step - g_loss: 1.6637 - d_loss: 0.4398 - d_acc: 0.8443\n",
      "Epoch 85/200\n",
      "467/467 [==============================] - 52s 112ms/step - g_loss: 1.6466 - d_loss: 0.4714 - d_acc: 0.8277\n",
      "Epoch 86/200\n",
      "467/467 [==============================] - 52s 111ms/step - g_loss: 1.6708 - d_loss: 0.4351 - d_acc: 0.8480\n",
      "Epoch 87/200\n",
      "467/467 [==============================] - 51s 110ms/step - g_loss: 1.6860 - d_loss: 0.4368 - d_acc: 0.8466\n",
      "Epoch 88/200\n",
      "467/467 [==============================] - 52s 112ms/step - g_loss: 1.6795 - d_loss: 0.4502 - d_acc: 0.8389\n",
      "Epoch 89/200\n",
      "467/467 [==============================] - 52s 112ms/step - g_loss: 1.6993 - d_loss: 0.4493 - d_acc: 0.8419\n",
      "Epoch 90/200\n",
      "467/467 [==============================] - ETA: 0s - g_loss: 1.6570 - d_loss: 0.4488 - d_acc: 0.8397\n",
      "\n",
      "Saving weights at epoch 90\n",
      "\n",
      "467/467 [==============================] - 59s 125ms/step - g_loss: 1.6570 - d_loss: 0.4488 - d_acc: 0.8397\n",
      "Epoch 91/200\n",
      "467/467 [==============================] - 51s 109ms/step - g_loss: 1.6803 - d_loss: 0.4504 - d_acc: 0.8401\n",
      "Epoch 92/200\n",
      "467/467 [==============================] - 51s 110ms/step - g_loss: 1.6838 - d_loss: 0.4300 - d_acc: 0.8517\n",
      "Epoch 93/200\n",
      "467/467 [==============================] - 52s 112ms/step - g_loss: 1.7192 - d_loss: 0.4304 - d_acc: 0.8515\n",
      "Epoch 94/200\n",
      "467/467 [==============================] - 49s 105ms/step - g_loss: 1.7135 - d_loss: 0.4376 - d_acc: 0.8471\n",
      "Epoch 95/200\n",
      "467/467 [==============================] - 46s 99ms/step - g_loss: 1.7172 - d_loss: 0.4457 - d_acc: 0.8443\n",
      "Epoch 96/200\n",
      "467/467 [==============================] - 51s 110ms/step - g_loss: 1.7220 - d_loss: 0.4239 - d_acc: 0.8566\n",
      "Epoch 97/200\n",
      "467/467 [==============================] - 52s 111ms/step - g_loss: 1.7333 - d_loss: 0.4413 - d_acc: 0.8467\n",
      "Epoch 98/200\n",
      "467/467 [==============================] - 52s 111ms/step - g_loss: 1.7368 - d_loss: 0.4248 - d_acc: 0.8553\n",
      "Epoch 99/200\n",
      "467/467 [==============================] - 51s 109ms/step - g_loss: 1.7214 - d_loss: 0.4489 - d_acc: 0.8438\n",
      "Epoch 100/200\n",
      "467/467 [==============================] - ETA: 0s - g_loss: 1.7541 - d_loss: 0.4212 - d_acc: 0.8581\n",
      "\n",
      "Saving weights at epoch 100\n",
      "\n",
      "467/467 [==============================] - 57s 123ms/step - g_loss: 1.7541 - d_loss: 0.4212 - d_acc: 0.8581\n",
      "Epoch 101/200\n",
      "467/467 [==============================] - 52s 112ms/step - g_loss: 1.7350 - d_loss: 0.4396 - d_acc: 0.8497\n",
      "Epoch 102/200\n",
      "467/467 [==============================] - 53s 113ms/step - g_loss: 1.7646 - d_loss: 0.4222 - d_acc: 0.8576\n",
      "Epoch 103/200\n",
      "467/467 [==============================] - 52s 111ms/step - g_loss: 1.7491 - d_loss: 0.4366 - d_acc: 0.8508\n",
      "Epoch 104/200\n",
      "467/467 [==============================] - 51s 109ms/step - g_loss: 1.7539 - d_loss: 0.4428 - d_acc: 0.8477\n",
      "Epoch 105/200\n",
      "467/467 [==============================] - 52s 111ms/step - g_loss: 1.7575 - d_loss: 0.4329 - d_acc: 0.8536\n",
      "Epoch 106/200\n",
      "467/467 [==============================] - 30s 64ms/step - g_loss: 1.7835 - d_loss: 0.4165 - d_acc: 0.8634\n",
      "Epoch 107/200\n",
      "467/467 [==============================] - 25s 55ms/step - g_loss: 1.7660 - d_loss: 0.4375 - d_acc: 0.8495\n",
      "Epoch 108/200\n",
      "141/467 [========>.....................] - ETA: 17s - g_loss: 1.8020 - d_loss: 0.4111 - d_acc: 0.8676"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = cdcgan.fit(dataset, epochs=EPOCHS, callbacks=callbacks, use_multiprocessing=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(history.history['d_loss'], label='disc_loss')\n",
    "plt.plot(history.history['g_loss'], label='gen_loss')\n",
    "\n",
    "plt.xlabel('Epochs', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(history.history['d_acc'], label='disc_acc')\n",
    "\n",
    "plt.xlabel('Epochs', fontsize=14)\n",
    "plt.ylabel('Accuracy', fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vectors = tf.random.normal(shape=(100, LATENT_DIM))\n",
    "class_labels = tf.reshape(tf.range(10), shape=(10, 1))\n",
    "class_labels = tf.tile(class_labels, multiples=(1, 10))\n",
    "class_labels = tf.reshape(class_labels, shape=(100, 1))\n",
    "\n",
    "generated_images = cdcgan.generator([latent_vectors, class_labels], training=False)\n",
    "generated_images = (generated_images + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(10, 10, figsize=(20, 20))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(generated_images[i], cmap='gray')\n",
    "    ax.set_title(label_map[class_labels[i].numpy().item()], fontsize=18)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Model and Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # export dcgan loss and acc results\n",
    "# if not os.path.exists('performance'):\n",
    "#     os.makedirs('performance')\n",
    "\n",
    "# cdcgan_perf = dict(\n",
    "#     g_loss=history.history['g_loss'],\n",
    "#     d_loss=history.history['d_loss'],\n",
    "#     d_acc=history.history['d_acc'],\n",
    "# )\n",
    "\n",
    "# with open('performance/cdcgan_perf.pickle', 'wb') as f:\n",
    "#     pickle.dump(cdcgan_perf, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open('performance/cdcgan_perf.pickle', 'rb') as f:\n",
    "#     unserialized_data = pickle.load(f)\n",
    "\n",
    "# assert cdcgan_perf == unserialized_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Radford, A., Metz, L. and Chintala, S. (2016) Unsupervised representation learning with deep convolutional generative Adversarial Networks, arXiv.org. Available at: https://arxiv.org/abs/1511.06434 (Accessed: January 8, 2023). \n",
    "\n",
    "[2] Mirza, M. and Osindero, S. (2014) Conditional generative adversarial nets, arXiv.org. Available at: https://arxiv.org/abs/1411.1784 (Accessed: January 8, 2023). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('gpu_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "666a1b6055a6d64029d3ba184b27518fce88fba32d5a3ee2ba82c9dc2fa1e9d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

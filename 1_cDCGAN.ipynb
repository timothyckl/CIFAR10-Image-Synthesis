{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Deep Convolutional Generative Adversarial Network (cDCGAN)\n",
    "\n",
    "This notebook will contain my implmentation of DCGAN from the paper [1] conditioning the generator and discriminator models  with label information, a concept introduced in [2]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from IPython import display\n",
    "from tensorflow.data import Dataset\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Conv2DTranspose, Embedding, Reshape, Flatten, Dropout, BatchNormalization, ReLU, LeakyReLU, MaxPooling2D, Concatenate\n",
    "\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from utils import FrechetInceptionDistance\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.dpi': 120})\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set gpu memory growth\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.uint8, name=None))\n"
     ]
    }
   ],
   "source": [
    "FILE_PATH = 'data\\cifar10.tfrecords'\n",
    "dataset = Dataset.load(FILE_PATH)\n",
    "print(dataset.element_spec)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator(latent_dim):\n",
    "    # foundation for label embeedded input\n",
    "    label_input = Input(shape=(1,), name='label_input')\n",
    "    label_embedding = Embedding(10, 10, name='label_embedding')(label_input)\n",
    "    \n",
    "    # linear activation\n",
    "    label_embedding = Dense(4 * 4, name='label_dense')(label_embedding)\n",
    "\n",
    "    # reshape to additional channel\n",
    "    label_embedding = Reshape((4, 4, 1), name='label_reshape')(label_embedding)\n",
    "    assert label_embedding.shape == (None, 4, 4, 1)\n",
    "\n",
    "    # foundation for 4x4 image input\n",
    "    noise_input = Input(shape=(latent_dim,), name='noise_input')\n",
    "    noise_dense = Dense(4 * 4 * 128, name='noise_dense')(noise_input)\n",
    "    noise_dense = ReLU(name='noise_relu')(noise_dense)\n",
    "    noise_reshape = Reshape((4, 4, 128), name='noise_reshape')(noise_dense)\n",
    "    assert noise_reshape.shape == (None, 4, 4, 128)\n",
    "\n",
    "    # concatenate label embedding and image to produce 129-channel output\n",
    "    concat = keras.layers.Concatenate(name='concatenate')([noise_reshape, label_embedding])\n",
    "    assert concat.shape == (None, 4, 4, 129)\n",
    "\n",
    "    # upsample to 8x8\n",
    "    conv1 = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', name='conv1')(concat)\n",
    "    assert conv1.shape == (None, 8, 8, 128)\n",
    "    conv1 = ReLU(name='conv1_relu')(conv1)\n",
    "\n",
    "    # upsample to 16x16\n",
    "    conv2 = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', name='conv2')(conv1)\n",
    "    assert conv2.shape == (None, 16, 16, 128)\n",
    "    conv2 = ReLU(name='conv2_relu')(conv2)\n",
    "\n",
    "    # upsample to 32x32\n",
    "    conv3 = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', name='conv3')(conv2)\n",
    "    assert conv3.shape == (None, 32, 32, 128)\n",
    "    conv3 = ReLU(name='conv3_relu')(conv3)\n",
    "    \n",
    "    # output 32x32x3\n",
    "    output = Conv2D(3, (3, 3), activation='tanh', padding='same', name='output')(conv3)\n",
    "    assert output.shape == (None, 32, 32, 3)\n",
    "\n",
    "    model = Model(inputs=[noise_input, label_input], outputs=output, name='generator')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " noise_input (InputLayer)       [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " label_input (InputLayer)       [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " noise_dense (Dense)            (None, 2048)         264192      ['noise_input[0][0]']            \n",
      "                                                                                                  \n",
      " label_embedding (Embedding)    (None, 1, 10)        100         ['label_input[0][0]']            \n",
      "                                                                                                  \n",
      " noise_relu (ReLU)              (None, 2048)         0           ['noise_dense[0][0]']            \n",
      "                                                                                                  \n",
      " label_dense (Dense)            (None, 1, 16)        176         ['label_embedding[0][0]']        \n",
      "                                                                                                  \n",
      " noise_reshape (Reshape)        (None, 4, 4, 128)    0           ['noise_relu[0][0]']             \n",
      "                                                                                                  \n",
      " label_reshape (Reshape)        (None, 4, 4, 1)      0           ['label_dense[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 4, 4, 129)    0           ['noise_reshape[0][0]',          \n",
      "                                                                  'label_reshape[0][0]']          \n",
      "                                                                                                  \n",
      " conv1 (Conv2DTranspose)        (None, 8, 8, 128)    264320      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv1_relu (ReLU)              (None, 8, 8, 128)    0           ['conv1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2 (Conv2DTranspose)        (None, 16, 16, 128)  262272      ['conv1_relu[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_relu (ReLU)              (None, 16, 16, 128)  0           ['conv2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv3 (Conv2DTranspose)        (None, 32, 32, 128)  262272      ['conv2_relu[0][0]']             \n",
      "                                                                                                  \n",
      " conv3_relu (ReLU)              (None, 32, 32, 128)  0           ['conv3[0][0]']                  \n",
      "                                                                                                  \n",
      " output (Conv2D)                (None, 32, 32, 3)    3459        ['conv3_relu[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,056,791\n",
      "Trainable params: 1,056,791\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "create_generator(latent_dim=128).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize generator\n",
    "# plot_model(generator, show_shapes=True, to_file='images\\model_architecture\\Conditional_DCGAN\\generator.png')\n",
    "# generator_img = mpimg.imread('images\\model_architecture\\Conditional_DCGAN\\generator.png')\n",
    "\n",
    "# plt.figure(figsize=(20, 20))\n",
    "# imgplot = plt.imshow(generator_img)\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discriminator():\n",
    "    # foundation for label embeedded input\n",
    "    label_input = Input(shape=(1,), name='label_input')\n",
    "    label_embedding = Embedding(10, 10, name='label_embedding')(label_input)\n",
    "    \n",
    "    # linear activation\n",
    "    label_embedding = Dense(32 * 32, name='label_dense')(label_embedding)\n",
    "    \n",
    "    # reshape to additional channel\n",
    "    label_embedding = Reshape((32, 32, 1), name='label_reshape')(label_embedding)\n",
    "    assert label_embedding.shape == (None, 32, 32, 1)\n",
    "\n",
    "    # foundation for 32x32 image input\n",
    "    image_input = Input(shape=(32, 32, 3), name='image_input')\n",
    "\n",
    "    # concatenate label embedding and image to produce 129-channel input\n",
    "    concat = keras.layers.Concatenate(name='concatenate')([image_input, label_embedding])\n",
    "    assert concat.shape == (None, 32, 32, 4)\n",
    "\n",
    "    # downsample to 16x16\n",
    "    conv1 = Conv2D(128, kernel_size=3, strides=2, padding='same', name='conv1')(concat)\n",
    "    assert conv1.shape == (None, 16, 16, 128)\n",
    "    conv1 = LeakyReLU(alpha=0.2, name='conv1_leaky_relu')(conv1)\n",
    "    \n",
    "    # downsample to 8x8\n",
    "    conv2 = Conv2D(128, kernel_size=3, strides=2, padding='same', name='conv2')(conv1)\n",
    "    assert conv2.shape == (None, 8, 8, 128)\n",
    "    conv2 = LeakyReLU(alpha=0.2, name='conv2_leaky_relu')(conv2)\n",
    "    \n",
    "    # downsample to 4x4\n",
    "    conv3 = Conv2D(128, kernel_size=3, strides=2, padding='same', name='conv3')(conv2)\n",
    "    assert conv3.shape == (None, 4, 4, 128)\n",
    "    conv3 = LeakyReLU(alpha=0.2, name='conv3_leaky_relu')(conv3)\n",
    "\n",
    "    # flatten feature maps\n",
    "    flat = Flatten(name='flatten')(conv3)\n",
    "    \n",
    "    output = Dense(units=1, activation='sigmoid', name='output')(flat)\n",
    "\n",
    "    model = Model(inputs=[image_input, label_input], outputs=output, name='discriminator')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " label_input (InputLayer)       [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " label_embedding (Embedding)    (None, 1, 10)        100         ['label_input[0][0]']            \n",
      "                                                                                                  \n",
      " label_dense (Dense)            (None, 1, 1024)      11264       ['label_embedding[0][0]']        \n",
      "                                                                                                  \n",
      " image_input (InputLayer)       [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " label_reshape (Reshape)        (None, 32, 32, 1)    0           ['label_dense[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 32, 32, 4)    0           ['image_input[0][0]',            \n",
      "                                                                  'label_reshape[0][0]']          \n",
      "                                                                                                  \n",
      " conv1 (Conv2D)                 (None, 16, 16, 128)  4736        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv1_leaky_relu (LeakyReLU)   (None, 16, 16, 128)  0           ['conv1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2 (Conv2D)                 (None, 8, 8, 128)    147584      ['conv1_leaky_relu[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_leaky_relu (LeakyReLU)   (None, 8, 8, 128)    0           ['conv2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv3 (Conv2D)                 (None, 4, 4, 128)    147584      ['conv2_leaky_relu[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_leaky_relu (LeakyReLU)   (None, 4, 4, 128)    0           ['conv3[0][0]']                  \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2048)         0           ['conv3_leaky_relu[0][0]']       \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            2049        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 313,317\n",
      "Trainable params: 313,317\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "create_discriminator().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize discriminator\n",
    "# plot_model(discriminator, show_shapes=True, to_file='images\\model_architecture\\Conditional_DCGAN\\discriminator.png')\n",
    "# discriminator_img = mpimg.imread('images\\model_architecture\\Conditional_DCGAN\\discriminator.png')\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# imgplot = plt.imshow(discriminator_img)\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining cDCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalDCGAN(Model):\n",
    "    def __init__(self, generator, discriminator, latent_dim):\n",
    "        super(ConditionalDCGAN, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(ConditionalDCGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.g_loss_metric = keras.metrics.Mean(name='g_loss')\n",
    "        self.d_loss_metric = keras.metrics.Mean(name='d_loss')\n",
    "        self.d_acc_metric = keras.metrics.BinaryAccuracy(name='d_acc')\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.g_loss_metric, self.d_loss_metric, self.d_acc_metric]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        real_images, class_labels = data\n",
    "        class_labels = tf.cast(class_labels, 'int32')\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "\n",
    "        # train discriminator\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_class_labels = tf.random.uniform(shape=(batch_size, 1), minval=0, maxval=10, dtype='int32')\n",
    "        generated_images = self.generator([random_latent_vectors, random_class_labels], training=False)\n",
    "\n",
    "        # combine real and generated images as well as real and generated labels\n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "        combined_class_labels = tf.concat([random_class_labels, class_labels], axis=0)\n",
    "\n",
    "        fake_labels = tf.zeros((batch_size, 1))  # (batch_size, 1)\n",
    "        real_labels = tf.ones((batch_size, 1))  # (batch_size, 1)\n",
    "        combined_labels = tf.concat([fake_labels, real_labels], axis=0)  # (2*batch_size, 1)\n",
    "\n",
    "        # train the discriminator\n",
    "        with tf.GradientTape() as disc_tape:\n",
    "            pred_on_combined = self.discriminator([combined_images, combined_class_labels], training=True)\n",
    "            d_loss = self.loss_fn(combined_labels, pred_on_combined)  # log(D(x)) + log(1 - D(G(z))\n",
    "        \n",
    "        disc_grads = disc_tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "        self.d_optimizer.apply_gradients(zip(disc_grads, self.discriminator.trainable_variables))\n",
    "\n",
    "        # train the generator\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_class_labels = tf.random.uniform(shape=(batch_size, 1), minval=0, maxval=10, dtype='int32')\n",
    "        misleading_labels = tf.ones((batch_size, 1))\n",
    "\n",
    "        with tf.GradientTape() as gen_tape:\n",
    "            pred_on_fake = self.discriminator([self.generator([random_latent_vectors, random_class_labels], training=True), random_class_labels], training=False)\n",
    "            g_loss = self.loss_fn(misleading_labels, pred_on_fake)  # maximize log(D(G(z))) = minimize -log(1 - D(G(z)))\n",
    "        \n",
    "        gen_grads = gen_tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        self.g_optimizer.apply_gradients(zip(gen_grads, self.generator.trainable_variables))\n",
    "\n",
    "        # update metrics\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        self.d_acc_metric.update_state(combined_labels, pred_on_combined)\n",
    "\n",
    "        return {\n",
    "            'g_loss': self.g_loss_metric.result(), \n",
    "            'd_loss': self.d_loss_metric.result(),\n",
    "            'd_acc': self.d_acc_metric.result()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANMonitor(Callback):\n",
    "    def __init__(self, latent_dim, label_map):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.label_map = label_map\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # every 10 epochs, save model weights\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            if not os.path.exists('assets/cdcgan'):\n",
    "                os.makedirs('assets/cdcgan')\n",
    "                \n",
    "            if not os.path.exists(f'assets/cdcgan/epoch_{epoch + 1}'):\n",
    "                os.makedirs(f'assets/cdcgan/epoch_{epoch + 1}')\n",
    "            \n",
    "            self.model.generator.save_weights(f'assets/cdcgan/epoch_{epoch + 1}/generator_weights_epoch_{epoch + 1}.h5')\n",
    "            self.model.discriminator.save_weights(f'assets/cdcgan/epoch_{epoch + 1}/discriminator_weights_epoch_{epoch + 1}.h5')\n",
    "            \n",
    "            print(f'\\n\\nSaving weights at epoch {epoch + 1}\\n')\n",
    "\n",
    "        # plot 100 generated images\n",
    "        latent_vectors = tf.random.normal(shape=(100, self.latent_dim))\n",
    "        class_labels = tf.reshape(tf.range(10), shape=(10, 1))\n",
    "        class_labels = tf.tile(class_labels, multiples=(1, 10))\n",
    "        class_labels = tf.reshape(class_labels, shape=(100, 1))\n",
    "\n",
    "        generated_images = self.model.generator([latent_vectors, class_labels], training=False)\n",
    "        generated_images = (generated_images + 1) / 2\n",
    "\n",
    "        if not os.path.exists('images/cdcgan_images'):\n",
    "            os.makedirs('images/cdcgan_images')\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            fig, axes = plt.subplots(10, 10, figsize=(20, 20))\n",
    "            axes = axes.flatten()\n",
    "\n",
    "            for i, ax in enumerate(axes):\n",
    "                ax.imshow(generated_images[i])\n",
    "                ax.set_title(self.label_map[class_labels[i].numpy().item()], fontsize=16)\n",
    "                ax.axis('off')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'images/cdcgan_images/generated_img_{epoch + 1}.png')\n",
    "            plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training cDCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "LATENT_DIM = 128    \n",
    "LEARNING_RATE = 2e-4\n",
    "BETA_1 = 0.5\n",
    "\n",
    "label_map = {\n",
    "    0: 'airplane',\n",
    "    1: 'automobile',\n",
    "    2: 'bird',\n",
    "    3: 'cat',\n",
    "    4: 'deer',\n",
    "    5: 'dog',\n",
    "    6: 'frog',\n",
    "    7: 'horse',\n",
    "    8: 'ship',\n",
    "    9: 'truck'\n",
    "}\n",
    "\n",
    "callbacks = [GANMonitor(LATENT_DIM, label_map)]\n",
    "\n",
    "generator = create_generator(LATENT_DIM)\n",
    "discriminator = create_discriminator()\n",
    "cdcgan = ConditionalDCGAN(generator, discriminator, latent_dim=LATENT_DIM)\n",
    "cdcgan.compile(\n",
    "    g_optimizer=Adam(learning_rate=LEARNING_RATE, beta_1=BETA_1),\n",
    "    d_optimizer=Adam(learning_rate=LEARNING_RATE, beta_1=BETA_1),\n",
    "    loss_fn=BinaryCrossentropy(label_smoothing=0.2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "469/469 [==============================] - 79s 136ms/step - g_loss: 1.6528 - d_loss: 0.5025 - d_acc: 0.8665\n",
      "Epoch 2/200\n",
      "469/469 [==============================] - 62s 133ms/step - g_loss: 1.6965 - d_loss: 0.4747 - d_acc: 0.8997\n",
      "Epoch 3/200\n",
      "469/469 [==============================] - 62s 133ms/step - g_loss: 1.5824 - d_loss: 0.4958 - d_acc: 0.8751\n",
      "Epoch 4/200\n",
      "469/469 [==============================] - 63s 134ms/step - g_loss: 1.4590 - d_loss: 0.5689 - d_acc: 0.7953\n",
      "Epoch 5/200\n",
      "469/469 [==============================] - 63s 134ms/step - g_loss: 1.4294 - d_loss: 0.5800 - d_acc: 0.7839\n",
      "Epoch 6/200\n",
      "469/469 [==============================] - 63s 134ms/step - g_loss: 1.4549 - d_loss: 0.5728 - d_acc: 0.7947\n",
      "Epoch 7/200\n",
      "469/469 [==============================] - 63s 134ms/step - g_loss: 1.5901 - d_loss: 0.5431 - d_acc: 0.8280\n",
      "Epoch 8/200\n",
      "469/469 [==============================] - 63s 135ms/step - g_loss: 1.6408 - d_loss: 0.5321 - d_acc: 0.8380\n",
      "Epoch 9/200\n",
      "469/469 [==============================] - 63s 135ms/step - g_loss: 1.7677 - d_loss: 0.5119 - d_acc: 0.8685\n",
      "Epoch 10/200\n",
      "469/469 [==============================] - ETA: 0s - g_loss: 1.6952 - d_loss: 0.5096 - d_acc: 0.8591\n",
      "\n",
      "Saving weights at epoch 10\n",
      "\n",
      "469/469 [==============================] - 72s 153ms/step - g_loss: 1.6952 - d_loss: 0.5096 - d_acc: 0.8591\n",
      "Epoch 11/200\n",
      "469/469 [==============================] - 64s 136ms/step - g_loss: 1.4896 - d_loss: 0.5551 - d_acc: 0.8039\n",
      "Epoch 12/200\n",
      "469/469 [==============================] - 64s 137ms/step - g_loss: 1.4901 - d_loss: 0.5503 - d_acc: 0.8081\n",
      "Epoch 13/200\n",
      "469/469 [==============================] - 64s 137ms/step - g_loss: 1.4292 - d_loss: 0.5589 - d_acc: 0.7917\n",
      "Epoch 14/200\n",
      "469/469 [==============================] - 64s 137ms/step - g_loss: 1.4359 - d_loss: 0.5577 - d_acc: 0.7971\n",
      "Epoch 15/200\n",
      "469/469 [==============================] - 64s 137ms/step - g_loss: 1.4042 - d_loss: 0.5584 - d_acc: 0.7908\n",
      "Epoch 16/200\n",
      "469/469 [==============================] - 67s 143ms/step - g_loss: 1.3877 - d_loss: 0.5551 - d_acc: 0.7951\n",
      "Epoch 17/200\n",
      "469/469 [==============================] - 70s 148ms/step - g_loss: 1.3466 - d_loss: 0.5701 - d_acc: 0.7729\n",
      "Epoch 18/200\n",
      "469/469 [==============================] - 70s 150ms/step - g_loss: 1.3778 - d_loss: 0.5609 - d_acc: 0.7834\n",
      "Epoch 19/200\n",
      "469/469 [==============================] - 65s 139ms/step - g_loss: 1.2699 - d_loss: 0.5730 - d_acc: 0.7686\n",
      "Epoch 20/200\n",
      "469/469 [==============================] - ETA: 0s - g_loss: 1.1952 - d_loss: 0.5875 - d_acc: 0.7503\n",
      "\n",
      "Saving weights at epoch 20\n",
      "\n",
      "469/469 [==============================] - 67s 143ms/step - g_loss: 1.1952 - d_loss: 0.5875 - d_acc: 0.7503\n",
      "Epoch 21/200\n",
      "469/469 [==============================] - 61s 130ms/step - g_loss: 1.1386 - d_loss: 0.5953 - d_acc: 0.7346\n",
      "Epoch 22/200\n",
      "469/469 [==============================] - 61s 129ms/step - g_loss: 1.0968 - d_loss: 0.6044 - d_acc: 0.7201\n",
      "Epoch 23/200\n",
      "469/469 [==============================] - 61s 129ms/step - g_loss: 1.0405 - d_loss: 0.6134 - d_acc: 0.7109\n",
      "Epoch 24/200\n",
      "469/469 [==============================] - 61s 129ms/step - g_loss: 1.0103 - d_loss: 0.6215 - d_acc: 0.6969\n",
      "Epoch 25/200\n",
      "469/469 [==============================] - 60s 129ms/step - g_loss: 0.9860 - d_loss: 0.6223 - d_acc: 0.6957\n",
      "Epoch 26/200\n",
      "469/469 [==============================] - 61s 129ms/step - g_loss: 0.9915 - d_loss: 0.6196 - d_acc: 0.7019\n",
      "Epoch 27/200\n",
      "469/469 [==============================] - 60s 128ms/step - g_loss: 0.9633 - d_loss: 0.6199 - d_acc: 0.7010\n",
      "Epoch 28/200\n",
      "469/469 [==============================] - 60s 128ms/step - g_loss: 1.0007 - d_loss: 0.6220 - d_acc: 0.6968\n",
      "Epoch 29/200\n",
      "469/469 [==============================] - 60s 128ms/step - g_loss: 0.9598 - d_loss: 0.6190 - d_acc: 0.7039\n",
      "Epoch 30/200\n",
      "469/469 [==============================] - ETA: 0s - g_loss: 0.9495 - d_loss: 0.6253 - d_acc: 0.6897\n",
      "\n",
      "Saving weights at epoch 30\n",
      "\n",
      "469/469 [==============================] - 66s 141ms/step - g_loss: 0.9495 - d_loss: 0.6253 - d_acc: 0.6897\n",
      "Epoch 31/200\n",
      "469/469 [==============================] - 60s 128ms/step - g_loss: 0.9332 - d_loss: 0.6312 - d_acc: 0.6815\n",
      "Epoch 32/200\n",
      "469/469 [==============================] - 60s 128ms/step - g_loss: 0.9367 - d_loss: 0.6314 - d_acc: 0.6789\n",
      "Epoch 33/200\n",
      "469/469 [==============================] - 60s 128ms/step - g_loss: 0.9195 - d_loss: 0.6350 - d_acc: 0.6738\n",
      "Epoch 34/200\n",
      "469/469 [==============================] - 60s 128ms/step - g_loss: 0.9132 - d_loss: 0.6384 - d_acc: 0.6660\n",
      "Epoch 35/200\n",
      "469/469 [==============================] - 60s 128ms/step - g_loss: 0.9076 - d_loss: 0.6375 - d_acc: 0.6675\n",
      "Epoch 36/200\n",
      "469/469 [==============================] - 60s 128ms/step - g_loss: 0.9018 - d_loss: 0.6370 - d_acc: 0.6694\n",
      "Epoch 37/200\n",
      "469/469 [==============================] - 60s 129ms/step - g_loss: 0.9069 - d_loss: 0.6371 - d_acc: 0.6689\n",
      "Epoch 38/200\n",
      "469/469 [==============================] - 60s 128ms/step - g_loss: 0.8879 - d_loss: 0.6405 - d_acc: 0.6633\n",
      "Epoch 39/200\n",
      "469/469 [==============================] - 60s 128ms/step - g_loss: 0.8752 - d_loss: 0.6419 - d_acc: 0.6603\n",
      "Epoch 40/200\n",
      "469/469 [==============================] - ETA: 0s - g_loss: 0.8735 - d_loss: 0.6457 - d_acc: 0.6550\n",
      "\n",
      "Saving weights at epoch 40\n",
      "\n",
      "469/469 [==============================] - 66s 141ms/step - g_loss: 0.8735 - d_loss: 0.6457 - d_acc: 0.6550\n",
      "Epoch 41/200\n",
      "469/469 [==============================] - 60s 128ms/step - g_loss: 0.8678 - d_loss: 0.6461 - d_acc: 0.6534\n",
      "Epoch 42/200\n",
      "469/469 [==============================] - 60s 128ms/step - g_loss: 0.8707 - d_loss: 0.6454 - d_acc: 0.6541\n",
      "Epoch 43/200\n",
      "469/469 [==============================] - 60s 128ms/step - g_loss: 0.8689 - d_loss: 0.6443 - d_acc: 0.6565\n",
      "Epoch 44/200\n",
      "469/469 [==============================] - 60s 128ms/step - g_loss: 0.8672 - d_loss: 0.6444 - d_acc: 0.6561\n",
      "Epoch 45/200\n",
      "469/469 [==============================] - 60s 128ms/step - g_loss: 0.8681 - d_loss: 0.6444 - d_acc: 0.6560\n",
      "Epoch 46/200\n",
      "469/469 [==============================] - 60s 128ms/step - g_loss: 0.8706 - d_loss: 0.6415 - d_acc: 0.6603\n",
      "Epoch 47/200\n",
      "469/469 [==============================] - 60s 128ms/step - g_loss: 0.8723 - d_loss: 0.6411 - d_acc: 0.6637\n",
      "Epoch 48/200\n",
      "469/469 [==============================] - 60s 128ms/step - g_loss: 0.8808 - d_loss: 0.6379 - d_acc: 0.6697\n",
      "Epoch 49/200\n",
      "469/469 [==============================] - 60s 128ms/step - g_loss: 0.8818 - d_loss: 0.6346 - d_acc: 0.6763\n",
      "Epoch 50/200\n",
      "469/469 [==============================] - ETA: 0s - g_loss: 0.8841 - d_loss: 0.6348 - d_acc: 0.6738\n",
      "\n",
      "Saving weights at epoch 50\n",
      "\n",
      "469/469 [==============================] - 65s 139ms/step - g_loss: 0.8841 - d_loss: 0.6348 - d_acc: 0.6738\n",
      "Epoch 51/200\n",
      "469/469 [==============================] - 60s 128ms/step - g_loss: 0.8906 - d_loss: 0.6331 - d_acc: 0.6769\n",
      "Epoch 52/200\n",
      "469/469 [==============================] - 60s 128ms/step - g_loss: 0.8909 - d_loss: 0.6327 - d_acc: 0.6760\n",
      "Epoch 53/200\n",
      "469/469 [==============================] - 60s 128ms/step - g_loss: 0.8878 - d_loss: 0.6316 - d_acc: 0.6784\n",
      "Epoch 54/200\n",
      "469/469 [==============================] - 60s 128ms/step - g_loss: 0.8952 - d_loss: 0.6314 - d_acc: 0.6799\n",
      "Epoch 55/200\n",
      "469/469 [==============================] - 60s 128ms/step - g_loss: 0.8983 - d_loss: 0.6289 - d_acc: 0.6825\n",
      "Epoch 56/200\n",
      "469/469 [==============================] - 62s 132ms/step - g_loss: 0.9008 - d_loss: 0.6288 - d_acc: 0.6804\n",
      "Epoch 57/200\n",
      "469/469 [==============================] - 61s 130ms/step - g_loss: 0.8946 - d_loss: 0.6283 - d_acc: 0.6832\n",
      "Epoch 58/200\n",
      "469/469 [==============================] - 61s 130ms/step - g_loss: 0.9014 - d_loss: 0.6304 - d_acc: 0.6800\n",
      "Epoch 59/200\n",
      "469/469 [==============================] - 61s 130ms/step - g_loss: 0.8985 - d_loss: 0.6285 - d_acc: 0.6845\n",
      "Epoch 60/200\n",
      "469/469 [==============================] - ETA: 0s - g_loss: 0.8969 - d_loss: 0.6296 - d_acc: 0.6813\n",
      "\n",
      "Saving weights at epoch 60\n",
      "\n",
      "469/469 [==============================] - 67s 144ms/step - g_loss: 0.8969 - d_loss: 0.6296 - d_acc: 0.6813\n",
      "Epoch 61/200\n",
      "469/469 [==============================] - 61s 130ms/step - g_loss: 0.8977 - d_loss: 0.6283 - d_acc: 0.6850\n",
      "Epoch 62/200\n",
      "469/469 [==============================] - 61s 130ms/step - g_loss: 0.8946 - d_loss: 0.6278 - d_acc: 0.6844\n",
      "Epoch 63/200\n",
      "469/469 [==============================] - 63s 134ms/step - g_loss: 0.9060 - d_loss: 0.6272 - d_acc: 0.6857\n",
      "Epoch 64/200\n",
      "469/469 [==============================] - 61s 130ms/step - g_loss: 0.9042 - d_loss: 0.6278 - d_acc: 0.6850\n",
      "Epoch 65/200\n",
      "469/469 [==============================] - 61s 130ms/step - g_loss: 0.9084 - d_loss: 0.6241 - d_acc: 0.6908\n",
      "Epoch 66/200\n",
      "469/469 [==============================] - 61s 131ms/step - g_loss: 0.9117 - d_loss: 0.6238 - d_acc: 0.6903\n",
      "Epoch 67/200\n",
      "469/469 [==============================] - 61s 130ms/step - g_loss: 0.9124 - d_loss: 0.6213 - d_acc: 0.6947\n",
      "Epoch 68/200\n",
      "469/469 [==============================] - 61s 130ms/step - g_loss: 0.9157 - d_loss: 0.6219 - d_acc: 0.6930\n",
      "Epoch 69/200\n",
      "469/469 [==============================] - 61s 129ms/step - g_loss: 0.9167 - d_loss: 0.6207 - d_acc: 0.6941\n",
      "Epoch 70/200\n",
      "469/469 [==============================] - ETA: 0s - g_loss: 0.9137 - d_loss: 0.6211 - d_acc: 0.6949\n",
      "\n",
      "Saving weights at epoch 70\n",
      "\n",
      "469/469 [==============================] - 68s 146ms/step - g_loss: 0.9137 - d_loss: 0.6211 - d_acc: 0.6949\n",
      "Epoch 71/200\n",
      "469/469 [==============================] - 62s 131ms/step - g_loss: 0.9176 - d_loss: 0.6204 - d_acc: 0.6959\n",
      "Epoch 72/200\n",
      "469/469 [==============================] - 61s 130ms/step - g_loss: 0.9219 - d_loss: 0.6183 - d_acc: 0.6997\n",
      "Epoch 73/200\n",
      "469/469 [==============================] - 60s 129ms/step - g_loss: 0.9288 - d_loss: 0.6189 - d_acc: 0.6985\n",
      "Epoch 74/200\n",
      "469/469 [==============================] - 61s 130ms/step - g_loss: 0.9259 - d_loss: 0.6168 - d_acc: 0.7018\n",
      "Epoch 75/200\n",
      "469/469 [==============================] - 61s 130ms/step - g_loss: 0.9251 - d_loss: 0.6171 - d_acc: 0.7012\n",
      "Epoch 76/200\n",
      "469/469 [==============================] - 61s 130ms/step - g_loss: 0.9262 - d_loss: 0.6157 - d_acc: 0.7023\n",
      "Epoch 77/200\n",
      "469/469 [==============================] - 61s 130ms/step - g_loss: 0.9293 - d_loss: 0.6140 - d_acc: 0.7069\n",
      "Epoch 78/200\n",
      "469/469 [==============================] - 61s 130ms/step - g_loss: 0.9387 - d_loss: 0.6118 - d_acc: 0.7096\n",
      "Epoch 79/200\n",
      "469/469 [==============================] - 61s 130ms/step - g_loss: 0.9442 - d_loss: 0.6131 - d_acc: 0.7073\n",
      "Epoch 80/200\n",
      "469/469 [==============================] - ETA: 0s - g_loss: 0.9339 - d_loss: 0.6106 - d_acc: 0.7111\n",
      "\n",
      "Saving weights at epoch 80\n",
      "\n",
      "469/469 [==============================] - 68s 145ms/step - g_loss: 0.9339 - d_loss: 0.6106 - d_acc: 0.7111\n",
      "Epoch 81/200\n",
      "469/469 [==============================] - 62s 131ms/step - g_loss: 0.9397 - d_loss: 0.6107 - d_acc: 0.7111\n",
      "Epoch 82/200\n",
      "469/469 [==============================] - 61s 130ms/step - g_loss: 0.9468 - d_loss: 0.6083 - d_acc: 0.7149\n",
      "Epoch 83/200\n",
      "469/469 [==============================] - 61s 130ms/step - g_loss: 0.9498 - d_loss: 0.6076 - d_acc: 0.7154\n",
      "Epoch 84/200\n",
      "469/469 [==============================] - 61s 129ms/step - g_loss: 0.9506 - d_loss: 0.6080 - d_acc: 0.7159\n",
      "Epoch 85/200\n",
      "469/469 [==============================] - 66s 140ms/step - g_loss: 0.9559 - d_loss: 0.6056 - d_acc: 0.7180\n",
      "Epoch 86/200\n",
      "469/469 [==============================] - 62s 131ms/step - g_loss: 0.9607 - d_loss: 0.6057 - d_acc: 0.7203\n",
      "Epoch 87/200\n",
      "469/469 [==============================] - 64s 136ms/step - g_loss: 0.9648 - d_loss: 0.6040 - d_acc: 0.7205\n",
      "Epoch 88/200\n",
      "469/469 [==============================] - 61s 130ms/step - g_loss: 0.9681 - d_loss: 0.6012 - d_acc: 0.7252\n",
      "Epoch 89/200\n",
      "469/469 [==============================] - 60s 129ms/step - g_loss: 0.9718 - d_loss: 0.5996 - d_acc: 0.7286\n",
      "Epoch 90/200\n",
      "469/469 [==============================] - ETA: 0s - g_loss: 0.9770 - d_loss: 0.6019 - d_acc: 0.7247\n",
      "\n",
      "Saving weights at epoch 90\n",
      "\n",
      "469/469 [==============================] - 67s 143ms/step - g_loss: 0.9770 - d_loss: 0.6019 - d_acc: 0.7247\n",
      "Epoch 91/200\n",
      "469/469 [==============================] - 60s 128ms/step - g_loss: 0.9727 - d_loss: 0.6007 - d_acc: 0.7261\n",
      "Epoch 92/200\n",
      "469/469 [==============================] - 60s 128ms/step - g_loss: 0.9831 - d_loss: 0.5985 - d_acc: 0.7298\n",
      "Epoch 93/200\n",
      "469/469 [==============================] - 60s 129ms/step - g_loss: 0.9780 - d_loss: 0.5967 - d_acc: 0.7343\n",
      "Epoch 94/200\n",
      "469/469 [==============================] - 132s 282ms/step - g_loss: 0.9984 - d_loss: 0.5938 - d_acc: 0.7372\n",
      "Epoch 95/200\n",
      "469/469 [==============================] - 146s 311ms/step - g_loss: 0.9978 - d_loss: 0.5931 - d_acc: 0.7361\n",
      "Epoch 96/200\n",
      "469/469 [==============================] - 145s 309ms/step - g_loss: 1.0064 - d_loss: 0.5899 - d_acc: 0.7416\n",
      "Epoch 97/200\n",
      "469/469 [==============================] - 143s 305ms/step - g_loss: 1.0042 - d_loss: 0.5953 - d_acc: 0.7351\n",
      "Epoch 98/200\n",
      "469/469 [==============================] - 147s 312ms/step - g_loss: 1.0095 - d_loss: 0.5878 - d_acc: 0.7461\n",
      "Epoch 99/200\n",
      "469/469 [==============================] - 145s 309ms/step - g_loss: 1.0045 - d_loss: 0.5859 - d_acc: 0.7475\n",
      "Epoch 100/200\n",
      "469/469 [==============================] - ETA: 0s - g_loss: 1.0186 - d_loss: 0.5881 - d_acc: 0.7435\n",
      "\n",
      "Saving weights at epoch 100\n",
      "\n",
      "469/469 [==============================] - 151s 323ms/step - g_loss: 1.0186 - d_loss: 0.5881 - d_acc: 0.7435\n",
      "Epoch 101/200\n",
      "469/469 [==============================] - 141s 301ms/step - g_loss: 1.0181 - d_loss: 0.5869 - d_acc: 0.7448\n",
      "Epoch 102/200\n",
      "469/469 [==============================] - 141s 301ms/step - g_loss: 1.0217 - d_loss: 0.5837 - d_acc: 0.7490\n",
      "Epoch 103/200\n",
      "469/469 [==============================] - 143s 305ms/step - g_loss: 1.0299 - d_loss: 0.5819 - d_acc: 0.7517\n",
      "Epoch 104/200\n",
      "469/469 [==============================] - 141s 301ms/step - g_loss: 1.0354 - d_loss: 0.5846 - d_acc: 0.7483\n",
      "Epoch 105/200\n",
      "469/469 [==============================] - 141s 300ms/step - g_loss: 1.0382 - d_loss: 0.5812 - d_acc: 0.7539\n",
      "Epoch 106/200\n",
      "469/469 [==============================] - 141s 300ms/step - g_loss: 1.0447 - d_loss: 0.5787 - d_acc: 0.7569\n",
      "Epoch 107/200\n",
      "469/469 [==============================] - 137s 292ms/step - g_loss: 1.0482 - d_loss: 0.5788 - d_acc: 0.7576\n",
      "Epoch 108/200\n",
      "469/469 [==============================] - 60s 129ms/step - g_loss: 1.0501 - d_loss: 0.5762 - d_acc: 0.7604\n",
      "Epoch 109/200\n",
      "469/469 [==============================] - 61s 129ms/step - g_loss: 1.0590 - d_loss: 0.5745 - d_acc: 0.7624\n",
      "Epoch 110/200\n",
      "469/469 [==============================] - ETA: 0s - g_loss: 1.0563 - d_loss: 0.5739 - d_acc: 0.7632\n",
      "\n",
      "Saving weights at epoch 110\n",
      "\n",
      "469/469 [==============================] - 68s 144ms/step - g_loss: 1.0563 - d_loss: 0.5739 - d_acc: 0.7632\n",
      "Epoch 111/200\n",
      "469/469 [==============================] - 61s 130ms/step - g_loss: 1.0630 - d_loss: 0.5774 - d_acc: 0.7583\n",
      "Epoch 112/200\n",
      "469/469 [==============================] - 61s 130ms/step - g_loss: 1.0698 - d_loss: 0.5740 - d_acc: 0.7622\n",
      "Epoch 113/200\n",
      "469/469 [==============================] - 61s 130ms/step - g_loss: 1.0643 - d_loss: 0.5747 - d_acc: 0.7630\n",
      "Epoch 114/200\n",
      "469/469 [==============================] - 61s 131ms/step - g_loss: 1.0718 - d_loss: 0.5695 - d_acc: 0.7687\n",
      "Epoch 115/200\n",
      "469/469 [==============================] - 61s 130ms/step - g_loss: 1.0716 - d_loss: 0.5668 - d_acc: 0.7729\n",
      "Epoch 116/200\n",
      "469/469 [==============================] - 62s 133ms/step - g_loss: 1.0761 - d_loss: 0.5707 - d_acc: 0.7689\n",
      "Epoch 117/200\n",
      "469/469 [==============================] - 62s 132ms/step - g_loss: 1.0701 - d_loss: 0.5697 - d_acc: 0.7683\n",
      "Epoch 118/200\n",
      "469/469 [==============================] - 61s 130ms/step - g_loss: 1.0907 - d_loss: 0.5680 - d_acc: 0.7700\n",
      "Epoch 119/200\n",
      "469/469 [==============================] - 63s 134ms/step - g_loss: 1.0836 - d_loss: 0.5774 - d_acc: 0.7622\n",
      "Epoch 120/200\n",
      "469/469 [==============================] - ETA: 0s - g_loss: 1.0871 - d_loss: 0.5648 - d_acc: 0.7751\n",
      "\n",
      "Saving weights at epoch 120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = cdcgan.fit(dataset, epochs=EPOCHS, callbacks=callbacks, use_multiprocessing=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(history.history['d_loss'], label='disc_loss')\n",
    "plt.plot(history.history['g_loss'], label='gen_loss')\n",
    "\n",
    "plt.xlabel('Epochs', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(history.history['d_acc'], label='disc_acc')\n",
    "\n",
    "plt.xlabel('Epochs', fontsize=14)\n",
    "plt.ylabel('Accuracy', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vectors = tf.random.normal(shape=(100, LATENT_DIM))\n",
    "class_labels = tf.reshape(tf.range(10), shape=(10, 1))\n",
    "class_labels = tf.tile(class_labels, multiples=(1, 10))\n",
    "class_labels = tf.reshape(class_labels, shape=(100, 1))\n",
    "\n",
    "generated_images = cdcgan.generator([latent_vectors, class_labels], training=False)\n",
    "generated_images = (generated_images + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(10, 10, figsize=(20, 20))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(generated_images[i], cmap='gray')\n",
    "    ax.set_title(label_map[class_labels[i].numpy().item()], fontsize=18)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Model and Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # export dcgan loss and acc results\n",
    "# if not os.path.exists('performance'):\n",
    "#     os.makedirs('performance')\n",
    "\n",
    "# cdcgan_perf = dict(\n",
    "#     g_loss=history.history['g_loss'],\n",
    "#     d_loss=history.history['d_loss'],\n",
    "#     d_acc=history.history['d_acc'],\n",
    "# )\n",
    "\n",
    "# with open('performance/cdcgan_perf.pickle', 'wb') as f:\n",
    "#     pickle.dump(cdcgan_perf, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open('performance/cdcgan_perf.pickle', 'rb') as f:\n",
    "#     unserialized_data = pickle.load(f)\n",
    "\n",
    "# assert cdcgan_perf == unserialized_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Radford, A., Metz, L. and Chintala, S. (2016) Unsupervised representation learning with deep convolutional generative Adversarial Networks, arXiv.org. Available at: https://arxiv.org/abs/1511.06434 (Accessed: January 8, 2023). \n",
    "\n",
    "[2] Mirza, M. and Osindero, S. (2014) Conditional generative adversarial nets, arXiv.org. Available at: https://arxiv.org/abs/1411.1784 (Accessed: January 8, 2023). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "666a1b6055a6d64029d3ba184b27518fce88fba32d5a3ee2ba82c9dc2fa1e9d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
